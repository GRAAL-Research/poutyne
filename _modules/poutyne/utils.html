<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>poutyne.utils &mdash; Poutyne 1.14 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html">
            <img src="../../_static/poutyne-light.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                1.14
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../model.html">Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../experiment.html">Experiment and ModelBundle</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../metrics.html">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../callbacks.html">Callbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../layers.html">Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../utils.html">Utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../examples/introduction.html">Introduction to PyTorch and Poutyne</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/tips_and_tricks.html">Tips and Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/sequence_tagging.html">Sequence Tagging With an RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/policy_interface.html">Interface of <code class="docutils literal notranslate"><span class="pre">policy</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/transfer_learning.html">Transfer learning example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/image_reconstruction.html">Image Reconstruction Using Poutyne</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/classification_and_regression.html">Gender Classification and Eyes Location Detection: A Two Task Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/semantic_segmentation.html">Semantic segmentation using Poutyne</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Poutyne</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">poutyne.utils</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for poutyne.utils</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Copyright (c) 2022 Poutyne and all respective contributors.</span>

<span class="sd">Each contributor holds copyright over their respective contributions. The project versioning (Git)</span>
<span class="sd">records all such contribution source information.</span>

<span class="sd">This file is part of Poutyne.</span>

<span class="sd">Poutyne is free software: you can redistribute it and/or modify it under the terms of the GNU Lesser General Public</span>
<span class="sd">License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later</span>
<span class="sd">version.</span>

<span class="sd">Poutyne is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty</span>
<span class="sd">of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details.</span>

<span class="sd">You should have received a copy of the GNU Lesser General Public License along with Poutyne. If not, see</span>
<span class="sd">&lt;https://www.gnu.org/licenses/&gt;.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># -*- coding: utf-8 -*-</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numbers</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">IO</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">BinaryIO</span><span class="p">,</span> <span class="n">Union</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.nn.utils.rnn</span> <span class="kn">import</span> <span class="n">PackedSequence</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>

<span class="kn">from</span> <span class="nn">.warning_manager</span> <span class="kn">import</span> <span class="n">warning_settings</span>


<div class="viewcode-block" id="torch_to_numpy"><a class="viewcode-back" href="../../utils.html#poutyne.torch_to_numpy">[docs]</a><span class="k">def</span> <span class="nf">torch_to_numpy</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert to Numpy arrays all tensors inside a Python object composed of the supported types.</span>

<span class="sd">    Args:</span>
<span class="sd">        obj: The Python object to convert.</span>
<span class="sd">        copy (bool): Whether to copy the memory. By default, if a tensor is already on CPU, the</span>
<span class="sd">            Numpy array will be a view of the tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A new Python object with the same structure as `obj` but where the tensors are now Numpy</span>
<span class="sd">        arrays. Not supported type are left as reference in the new object.</span>

<span class="sd">    Example:</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            &gt;&gt;&gt; from poutyne import torch_to_numpy</span>
<span class="sd">            &gt;&gt;&gt; torch_to_numpy({</span>
<span class="sd">            ...     &#39;first&#39;: torch.tensor([1, 2, 3]),</span>
<span class="sd">            ...     &#39;second&#39;:[torch.tensor([4,5,6]), torch.tensor([7,8,9])],</span>
<span class="sd">            ...     &#39;third&#39;: 34</span>
<span class="sd">            ... })</span>
<span class="sd">            {</span>
<span class="sd">                &#39;first&#39;: array([1, 2, 3]),</span>
<span class="sd">                &#39;second&#39;: [array([4, 5, 6]), array([7, 8, 9])],</span>
<span class="sd">                &#39;third&#39;: 34</span>
<span class="sd">            }</span>

<span class="sd">    See:</span>
<span class="sd">        :meth:`~poutyne.torch_apply` for supported types.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">copy</span><span class="p">:</span>

        <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">t</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="k">else</span><span class="p">:</span>

        <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">t</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">torch_apply</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">func</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">torch_to</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch_apply</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kargs</span><span class="p">))</span>


<div class="viewcode-block" id="torch_apply"><a class="viewcode-back" href="../../utils.html#poutyne.torch_apply">[docs]</a><span class="k">def</span> <span class="nf">torch_apply</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">func</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply a function to all tensors inside a Python object composed of the supported types.</span>

<span class="sd">    Supported types are: list, tuple and dict.</span>

<span class="sd">    Args:</span>
<span class="sd">        obj: The Python object to convert.</span>
<span class="sd">        func: The function to apply.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A new Python object with the same structure as `obj` but where the tensors have been applied</span>
<span class="sd">        the function `func`. Not supported type are left as reference in the new object.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">fn</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">else</span> <span class="n">t</span>

    <span class="k">return</span> <span class="n">_apply</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_apply</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">func</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">PackedSequence</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="n">obj</span><span class="p">)(</span>
                <span class="o">*</span><span class="p">(</span><span class="n">_apply</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">el</span><span class="p">),</span> <span class="n">func</span><span class="p">)</span> <span class="k">if</span> <span class="n">el</span> <span class="o">!=</span> <span class="s2">&quot;batch_sizes&quot;</span> <span class="k">else</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">el</span><span class="p">)</span> <span class="k">for</span> <span class="n">el</span> <span class="ow">in</span> <span class="n">obj</span><span class="o">.</span><span class="n">_fields</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="n">obj</span><span class="p">)(</span><span class="n">_apply</span><span class="p">(</span><span class="n">el</span><span class="p">,</span> <span class="n">func</span><span class="p">)</span> <span class="k">for</span> <span class="n">el</span> <span class="ow">in</span> <span class="n">obj</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">_apply</span><span class="p">(</span><span class="n">el</span><span class="p">,</span> <span class="n">func</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">el</span> <span class="ow">in</span> <span class="n">obj</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_concat</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
    <span class="n">first_item</span> <span class="o">=</span> <span class="n">obj</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">first_item</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="n">first_item</span><span class="p">)(</span><span class="n">_concat</span><span class="p">(</span><span class="n">ele</span><span class="p">)</span> <span class="k">for</span> <span class="n">ele</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">obj</span><span class="p">))</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">first_item</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">concat_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">first_item</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">concat_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">_concat</span><span class="p">([</span><span class="n">o</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">obj</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">concat_dict</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">first_item</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">first_item</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">first_item</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">first_item</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">obj</span>


<div class="viewcode-block" id="numpy_to_torch"><a class="viewcode-back" href="../../utils.html#poutyne.numpy_to_torch">[docs]</a><span class="k">def</span> <span class="nf">numpy_to_torch</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert to tensors all Numpy arrays inside a Python object composed of the supported types.</span>

<span class="sd">    Args:</span>
<span class="sd">        obj: The Python object to convert.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A new Python object with the same structure as `obj` but where the Numpy arrays are now</span>
<span class="sd">        tensors. Not supported type are left as reference in the new object.</span>

<span class="sd">    Example:</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            &gt;&gt;&gt; from poutyne import numpy_to_torch</span>
<span class="sd">            &gt;&gt;&gt; numpy_to_torch({</span>
<span class="sd">            ...     &#39;first&#39;: np.array([1, 2, 3]),</span>
<span class="sd">            ...     &#39;second&#39;:[np.array([4,5,6]), np.array([7,8,9])],</span>
<span class="sd">            ...     &#39;third&#39;: 34</span>
<span class="sd">            ... })</span>
<span class="sd">            {</span>
<span class="sd">                &#39;first&#39;: tensor([1, 2, 3]),</span>
<span class="sd">                &#39;second&#39;: [tensor([4, 5, 6]), tensor([7, 8, 9])],</span>
<span class="sd">                &#39;third&#39;: 34</span>
<span class="sd">            }</span>


<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">fn</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">else</span> <span class="n">a</span>

    <span class="k">return</span> <span class="n">_apply</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_assert_and_get_length_recursively</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="p">[</span><span class="n">_assert_and_get_length_recursively</span><span class="p">(</span><span class="n">o</span><span class="p">)</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">obj</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">length</span> <span class="ow">in</span> <span class="n">lengths</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
            <span class="k">assert</span> <span class="n">length</span> <span class="o">==</span> <span class="n">lengths</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">lengths</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_get_index_recursively</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="n">obj</span><span class="p">)(</span><span class="n">_get_index_recursively</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">obj</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">obj</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">TensorDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Dataset wrapping tensors.</span>

<span class="sd">    Each sample will be retrieved by indexing tensors along the first dimension.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        *tensors (Tensor): tensors that have the same size of the first dimension.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">tensors</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tensors</span> <span class="o">=</span> <span class="n">tensors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_len</span> <span class="o">=</span> <span class="n">_assert_and_get_length_recursively</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensors</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_get_index_recursively</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensors</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_len</span>


<div class="viewcode-block" id="set_seeds"><a class="viewcode-back" href="../../utils.html#poutyne.set_seeds">[docs]</a><span class="k">def</span> <span class="nf">set_seeds</span><span class="p">(</span><span class="n">seed</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Set Python, Numpy and Pytorch&#39;s random seeds in order to make</span>
<span class="sd">    the random number generation procedure deterministic and reproducible.</span>

<span class="sd">    Args:</span>
<span class="sd">        seed (int): The random number generation seed to use.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span></div>


<div class="viewcode-block" id="save_random_states"><a class="viewcode-back" href="../../utils.html#poutyne.save_random_states">[docs]</a><span class="k">def</span> <span class="nf">save_random_states</span><span class="p">(</span><span class="n">f</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="n">BinaryIO</span><span class="p">,</span> <span class="n">IO</span><span class="p">[</span><span class="nb">bytes</span><span class="p">]]):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Save Python, Numpy and Pytorch&#39;s (both CPU and GPU) random states.</span>

<span class="sd">    Args:</span>
<span class="sd">        f (Union[str, os.PathLike, BinaryIO, IO[bytes]]): a file-like object (has to implement write and flush) or</span>
<span class="sd">            a string or os.PathLike object containing a file name.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
        <span class="nb">dict</span><span class="p">(</span>
            <span class="n">cpu</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">get_rng_state</span><span class="p">(),</span>
            <span class="n">cuda</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_rng_state_all</span><span class="p">(),</span>
            <span class="n">numpy</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">get_state</span><span class="p">(),</span>
            <span class="n">python</span><span class="o">=</span><span class="n">random</span><span class="o">.</span><span class="n">getstate</span><span class="p">(),</span>
        <span class="p">),</span>
        <span class="n">f</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="load_random_states"><a class="viewcode-back" href="../../utils.html#poutyne.load_random_states">[docs]</a><span class="k">def</span> <span class="nf">load_random_states</span><span class="p">(</span><span class="n">f</span><span class="p">:</span> <span class="n">Any</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load Python, Numpy and Pytorch&#39;s (both CPU and GPU) random states as saved by :func:`~poutyne.save_random_states()`.</span>

<span class="sd">    Args:</span>
<span class="sd">        f: a file-like object (has to implement :meth:`read`, :meth:`readline`, :meth:`tell`, and :meth:`seek`),</span>
<span class="sd">            or a string or os.PathLike object containing a file name</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">states</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">set_rng_state</span><span class="p">(</span><span class="n">states</span><span class="p">[</span><span class="s2">&quot;cpu&quot;</span><span class="p">])</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_rng_state_all</span><span class="p">(</span><span class="n">states</span><span class="p">[</span><span class="s2">&quot;cuda&quot;</span><span class="p">])</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">states</span><span class="p">[</span><span class="s2">&quot;numpy&quot;</span><span class="p">])</span>
    <span class="n">random</span><span class="o">.</span><span class="n">setstate</span><span class="p">(</span><span class="n">states</span><span class="p">[</span><span class="s2">&quot;python&quot;</span><span class="p">])</span></div>


<span class="k">def</span> <span class="nf">is_in_jupyter_notebook</span><span class="p">():</span>
    <span class="c1"># pylint: disable=import-outside-toplevel</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">get_ipython</span>

        <span class="n">shell</span> <span class="o">=</span> <span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="n">jupyter</span> <span class="o">=</span> <span class="n">shell</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;ZMQInteractiveShell&#39;</span><span class="p">,</span> <span class="s1">&#39;Shell&#39;</span><span class="p">]</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="n">jupyter</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">return</span> <span class="n">jupyter</span>


<div class="viewcode-block" id="get_batch_size"><a class="viewcode-back" href="../../utils.html#poutyne.get_batch_size">[docs]</a><span class="k">def</span> <span class="nf">get_batch_size</span><span class="p">(</span><span class="o">*</span><span class="n">values</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This method infers the batch size of a batch. Here is the inferring algorithm used to compute the</span>
<span class="sd">    batch size. The values are tested in order at each step of the inferring algorithm. If one</span>
<span class="sd">    step succeed for one of the values, the algorithm stops.</span>

<span class="sd">    - Step 1: if a value is a tensor or a Numpy array, then the ``len()`` is returned.</span>
<span class="sd">    - Step 2: if a value is a list or a tuple, then the ``len()`` of the first element is returned</span>
<span class="sd">      if it is a tensor or a Numpy array.</span>
<span class="sd">    - Step 3: if a value is a dict, then the value for the key ``&#39;batch_size&#39;`` is returned if it</span>
<span class="sd">      is of integral type.</span>
<span class="sd">    - Step 4: if a value is a dict, then the ``len()`` of the first element of ``.values()`` is</span>
<span class="sd">      returned if it is a tensor or a Numpy array.</span>

<span class="sd">    If inferring the batch size is not possible, the batch size is set to 1 and a warning is raised.</span>
<span class="sd">    To disable this warning, set</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        from poutyne import warning_settings\n</span>
<span class="sd">        warning_settings[&#39;batch_size&#39;] = &#39;ignore&#39;\n\n</span>

<span class="sd">    Args:</span>
<span class="sd">        values: The values used for inferring the batch size.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">is_torch_or_numpy</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">is_torch_or_numpy</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">is_torch_or_numpy</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">if</span> <span class="s1">&#39;batch_size&#39;</span> <span class="ow">in</span> <span class="n">v</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">],</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">v</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">first_value</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">is_torch_or_numpy</span><span class="p">(</span><span class="n">first_value</span><span class="p">):</span>
                <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">first_value</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">warning_settings</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;warn&#39;</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;Inferring the batch size is not possible. Hence, the batch size is set to 1. To disable this warning, &quot;</span>
            <span class="s2">&quot;set</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="s2">&quot;from poutyne import warning_settings</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="s2">&quot;warning_settings[&#39;batch_size&#39;] = &#39;ignore&#39;</span><span class="se">\n\n</span><span class="s2">&quot;</span>
            <span class="c1">#</span>
            <span class="c1">#</span>
            <span class="s2">&quot;Here is the inferring algorithm used to compute the batch size. The values are tested in order at each &quot;</span>
            <span class="s2">&quot;step of the inferring algorithm. If one step succeed for one of the values, the algorithm stops.</span><span class="se">\n\n</span><span class="s2">&quot;</span>
            <span class="c1">#</span>
            <span class="c1">#</span>
            <span class="s2">&quot;Step 1: if a value is a tensor or a Numpy array, then the &#39;len()&#39; is returned.</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="c1">#</span>
            <span class="s2">&quot;Step 2: if a value is a list or a tuple, then the &#39;len()&#39; of the first element is returned if it is a &quot;</span>
            <span class="s2">&quot;tensor or a Numpy array.</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="c1">#</span>
            <span class="s2">&quot;Step 3: if a value is a dict, then the value for the key &#39;batch_size&#39; is returned if it is of integral &quot;</span>
            <span class="s2">&quot;type.</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="c1">#</span>
            <span class="s2">&quot;Step 4: if a value is a dict, then the &#39;len()&#39; of the first element of &#39;.values()&#39; is returned if it is a &quot;</span>
            <span class="s2">&quot;tensor or a Numpy array.</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="mi">1</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018-2022, Frédérik Paradis.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-177874682-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-177874682-1');
  gtag('config', 'G-VJM5JZMZ01');
</script>


</body>
</html>