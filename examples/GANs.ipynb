{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cef8cc2",
   "metadata": {},
   "source": [
    "# Training Conditional GANs Using Poutyne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bebbf9",
   "metadata": {},
   "source": [
    "This example shows how to use the Poutyne's strategy interface in order to deeply modify the training process internal to Poutyne.\n",
    "The main goal of Poutyne is to be very simple, yet flexible, to use.\n",
    "It does so by providing sane but customizable defaults.\n",
    "The aim of the strategy interface is to provide a lot of this flexibility in modifying the way Poutyne trains and evaluates your neural network.\n",
    "\n",
    "This example was adapted from the [Keras documentation](https://keras.io/examples/generative/conditional_gan/). The TensorFlow code was \"translated\" into PyTorch code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec4b3426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in /home/fredy/.venv/base/lib/python3.9/site-packages (2.22.3)\n",
      "Requirement already satisfied: numpy in /home/fredy/.venv/base/lib/python3.9/site-packages (from imageio) (1.23.4)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /home/fredy/.venv/base/lib/python3.9/site-packages (from imageio) (9.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aaee8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "import imageio.v3 as iio\n",
    "\n",
    "from poutyne import BaseStrategy, StepOutput, CumulativeAverage, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f8aae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_channels = 1\n",
    "num_classes = 10\n",
    "image_size = 28\n",
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4b7360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_percent = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46b7c4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_dataset = MNIST('./datasets', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = MNIST('./datasets', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "num_data = len(full_train_dataset)\n",
    "train_length = int(math.floor(train_split_percent * num_data))\n",
    "valid_length = num_data - train_length\n",
    "\n",
    "train_dataset, valid_dataset = random_split(\n",
    "    full_train_dataset, [train_length, valid_length], generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=2, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3426a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "969493bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af8745bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = nn.Sequential(\n",
    "    nn.Conv2d(discriminator_in_channels, 64, 3, stride=2, padding=1),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.AdaptiveMaxPool2d(1),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(128, 1),\n",
    ")\n",
    "\n",
    "generator = nn.Sequential(\n",
    "    nn.Linear(generator_in_channels, generator_in_channels * 7 * 7),\n",
    "    nn.Unflatten(1, (generator_in_channels, 7, 7)),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.ConvTranspose2d(generator_in_channels, 128, 4, stride=2, padding=1),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.ConvTranspose2d(128, 128, 4, stride=2, padding=1),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Conv2d(128, 1, 7, padding=3),\n",
    "    nn.Sigmoid(),\n",
    ")\n",
    "\n",
    "network = nn.ModuleDict(dict(discriminator=discriminator, generator=generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e51fe47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (discriminator): Sequential(\n",
       "    (0): Conv2d(11, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (3): LeakyReLU(negative_slope=0.2)\n",
       "    (4): AdaptiveMaxPool2d(output_size=1)\n",
       "    (5): Flatten(start_dim=1, end_dim=-1)\n",
       "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       "  (generator): Sequential(\n",
       "    (0): Linear(in_features=138, out_features=6762, bias=True)\n",
       "    (1): Unflatten(dim=1, unflattened_size=(138, 7, 7))\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "    (3): ConvTranspose2d(138, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.2)\n",
       "    (5): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): LeakyReLU(negative_slope=0.2)\n",
       "    (7): Conv2d(128, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (8): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8aa401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANStrategy(BaseStrategy):\n",
    "    def __init__(self, latent_dim, num_classes):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.batch_metrics_average = CumulativeAverage()\n",
    "\n",
    "    def get_batch_metric_names(self):\n",
    "        return ['g_loss', 'd_loss']\n",
    "\n",
    "    def compute_batch_metrics(self):\n",
    "        return self.batch_metrics_average.compute()\n",
    "\n",
    "    def reset_batch_metrics(self):\n",
    "        self.batch_metrics_average.reset()\n",
    "\n",
    "    def train_step(self, data, **kwargs):\n",
    "        return self._step(data, training=True, **kwargs)\n",
    "\n",
    "    def test_step(self, data, **kwargs):\n",
    "        # Implementing this method allows us to have a validation steps when\n",
    "        # training and enable us to call the evaluate* methods.\n",
    "        return self._step(data, training=False, **kwargs)\n",
    "\n",
    "    def _step(self, data, *, training=True, **kwargs):\n",
    "        # Unpack the data.\n",
    "        real_images, image_labels = data\n",
    "        discriminator = self.model.network.discriminator\n",
    "        generator = self.model.network.generator\n",
    "        discriminator_optimizer, generator_optimizer = self.model.optimizers\n",
    "        device = real_images.device\n",
    "\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the discriminator.\n",
    "        one_hot_labels = F.one_hot(image_labels, num_classes=self.num_classes)\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = image_one_hot_labels.expand(-1, -1, *real_images.shape[-2:])\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = real_images.shape[0]\n",
    "        random_latent_vectors = torch.randn((batch_size, self.latent_dim), device=device)\n",
    "        random_vector_labels = torch.cat((random_latent_vectors, one_hot_labels), axis=1)\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = torch.cat((generated_images, image_one_hot_labels), axis=1)\n",
    "        real_image_and_labels = torch.cat((real_images, image_one_hot_labels), axis=1)\n",
    "        combined_images = torch.cat((fake_image_and_labels, real_image_and_labels), axis=0)\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = torch.cat(\n",
    "            (torch.ones((batch_size, 1), device=device), torch.zeros((batch_size, 1), device=device)), axis=0\n",
    "        )\n",
    "        predictions = discriminator(combined_images)\n",
    "\n",
    "        d_loss = self.model.loss_function(predictions, labels)\n",
    "        if training:\n",
    "            discriminator_optimizer.zero_grad()\n",
    "            generator.zero_grad()\n",
    "            d_loss.backward()\n",
    "            discriminator_optimizer.step()\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = torch.randn((batch_size, self.latent_dim), device=device)\n",
    "        random_vector_labels = torch.cat((random_latent_vectors, one_hot_labels), axis=1)\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = torch.zeros((batch_size, 1), device=device)\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        fake_images = generator(random_vector_labels)\n",
    "        fake_image_and_labels = torch.cat((fake_images, image_one_hot_labels), axis=1)\n",
    "        predictions = discriminator(fake_image_and_labels)\n",
    "\n",
    "        g_loss = self.model.loss_function(predictions, misleading_labels)\n",
    "        if training:\n",
    "            discriminator.zero_grad()\n",
    "            generator_optimizer.zero_grad()\n",
    "            g_loss.backward()\n",
    "            generator_optimizer.step()\n",
    "\n",
    "        batch_metrics = [g_loss, d_loss]\n",
    "        self.batch_metrics_average.update(batch_metrics, batch_size)\n",
    "\n",
    "        return StepOutput(batch_metrics=batch_metrics, x=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0efb898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = GANStrategy(latent_dim, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24fbcaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=0.0003)\n",
    "generator_optimizer = optim.Adam(generator.parameters(), lr=0.0003)\n",
    "model = Model(\n",
    "    network, [discriminator_optimizer, generator_optimizer], 'bce_with_logits', strategy=strategy, device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a099e16e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mEpoch: \u001b[36m 1/20 \u001b[35mTrain steps: \u001b[36m750 \u001b[35mVal steps: \u001b[36m188 \u001b[32m24.42s \u001b[35mg_loss:\u001b[94m 0.893050\u001b[35m d_loss:\u001b[94m 0.607388\u001b[35m val_g_loss:\u001b[94m 0.699719\u001b[35m val_d_loss:\u001b[94m 0.755248\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 2/20 \u001b[35mTrain steps: \u001b[36m750 \u001b[35mVal steps: \u001b[36m188 \u001b[32m24.31s \u001b[35mg_loss:\u001b[94m 0.951307\u001b[35m d_loss:\u001b[94m 0.592437\u001b[35m val_g_loss:\u001b[94m 0.919600\u001b[35m val_d_loss:\u001b[94m 0.660756\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 3/20 \u001b[35mTrain steps: \u001b[36m750 \u001b[35mVal steps: \u001b[36m188 \u001b[32m24.39s \u001b[35mg_loss:\u001b[94m 2.940783\u001b[35m d_loss:\u001b[94m 0.272113\u001b[35m val_g_loss:\u001b[94m 1.395723\u001b[35m val_d_loss:\u001b[94m 0.457293\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 4/20 \u001b[35mTrain steps: \u001b[36m750 \u001b[35mVal steps: \u001b[36m188 \u001b[32m24.57s \u001b[35mg_loss:\u001b[94m 2.251616\u001b[35m d_loss:\u001b[94m 0.255573\u001b[35m val_g_loss:\u001b[94m 2.170500\u001b[35m val_d_loss:\u001b[94m 0.310764\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 5/20 \u001b[35mTrain steps: \u001b[36m750 \u001b[35mVal steps: \u001b[36m188 \u001b[32m24.58s \u001b[35mg_loss:\u001b[94m 2.967502\u001b[35m d_loss:\u001b[94m 0.156768\u001b[35m val_g_loss:\u001b[94m 3.251724\u001b[35m val_d_loss:\u001b[94m 0.115795\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 6/20 \u001b[35mTrain steps: \u001b[36m750 \u001b[35mVal steps: \u001b[36m188 \u001b[32m24.63s \u001b[35mg_loss:\u001b[94m 3.778930\u001b[35m d_loss:\u001b[94m 0.084587\u001b[35m val_g_loss:\u001b[94m 3.897270\u001b[35m val_d_loss:\u001b[94m 0.062823\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 7/20 \u001b[35mTrain steps: \u001b[36m750 \u001b[35mVal steps: \u001b[36m188 \u001b[32m24.61s \u001b[35mg_loss:\u001b[94m 4.505677\u001b[35m d_loss:\u001b[94m 0.049980\u001b[35m val_g_loss:\u001b[94m 4.477675\u001b[35m val_d_loss:\u001b[94m 0.044684\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 8/20 \u001b[35mTrain steps: \u001b[36m750 \u001b[35mVal steps: \u001b[36m188 \u001b[32m24.69s \u001b[35mg_loss:\u001b[94m 4.991932\u001b[35m d_loss:\u001b[94m 0.039344\u001b[35m val_g_loss:\u001b[94m 5.009208\u001b[35m val_d_loss:\u001b[94m 0.039360\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 9/20 \u001b[35mTrain steps: \u001b[36m750 \u001b[35mVal steps: \u001b[36m188 \u001b[32m24.67s \u001b[35mg_loss:\u001b[94m 2.981083\u001b[35m d_loss:\u001b[94m 0.288308\u001b[35m val_g_loss:\u001b[94m 1.355189\u001b[35m val_d_loss:\u001b[94m 0.438510\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m10/20 \u001b[35mTrain steps: \u001b[36m750 \u001b[35mVal steps: \u001b[36m188 \u001b[32m24.71s \u001b[35mg_loss:\u001b[94m 1.534124\u001b[35m d_loss:\u001b[94m 0.433013\u001b[35m val_g_loss:\u001b[94m 1.274686\u001b[35m val_d_loss:\u001b[94m 0.457419\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m11/20 \u001b[35mTrain steps: \u001b[36m750 \u001b[35mVal steps: \u001b[36m188 \u001b[32m24.78s \u001b[35mg_loss:\u001b[94m 1.340931\u001b[35m d_loss:\u001b[94m 0.470805\u001b[35m val_g_loss:\u001b[94m 1.197511\u001b[35m val_d_loss:\u001b[94m 0.492800\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m12/20 \u001b[35mTrain steps: \u001b[36m750 \u001b[35mVal steps: \u001b[36m188 \u001b[32m24.72s \u001b[35mg_loss:\u001b[94m 1.270963\u001b[35m d_loss:\u001b[94m 0.492525\u001b[35m val_g_loss:\u001b[94m 1.380618\u001b[35m val_d_loss:\u001b[94m 0.460530\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m13/20 \u001b[35mTrain steps: \u001b[36m750 \u001b[35mVal steps: \u001b[36m188 \u001b[32m24.78s \u001b[35mg_loss:\u001b[94m 1.226625\u001b[35m d_loss:\u001b[94m 0.502994\u001b[35m val_g_loss:\u001b[94m 0.940244\u001b[35m val_d_loss:\u001b[94m 0.523869\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m14/20 \u001b[35mTrain steps: \u001b[36m750 \u001b[35mVal steps: \u001b[36m188 \u001b[32m24.88s \u001b[35mg_loss:\u001b[94m 1.206472\u001b[35m d_loss:\u001b[94m 0.509094\u001b[35m val_g_loss:\u001b[94m 0.912299\u001b[35m val_d_loss:\u001b[94m 0.519916\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m15/20 \u001b[35mTrain steps: \u001b[36m750 \u001b[35mVal steps: \u001b[36m188 \u001b[32m24.92s \u001b[35mg_loss:\u001b[94m 1.223651\u001b[35m d_loss:\u001b[94m 0.510211\u001b[35m val_g_loss:\u001b[94m 0.907854\u001b[35m val_d_loss:\u001b[94m 0.542980\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m16/20 \u001b[35mTrain steps: \u001b[36m750 \u001b[35mVal steps: \u001b[36m188 \u001b[32m24.88s \u001b[35mg_loss:\u001b[94m 1.175883\u001b[35m d_loss:\u001b[94m 0.529804\u001b[35m val_g_loss:\u001b[94m 1.247158\u001b[35m val_d_loss:\u001b[94m 0.549094\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m17/20 \u001b[35mTrain steps: \u001b[36m750 \u001b[35mVal steps: \u001b[36m188 \u001b[32m24.90s \u001b[35mg_loss:\u001b[94m 1.130421\u001b[35m d_loss:\u001b[94m 0.552863\u001b[35m val_g_loss:\u001b[94m 0.971816\u001b[35m val_d_loss:\u001b[94m 0.578380\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m18/20 \u001b[35mTrain steps: \u001b[36m750 \u001b[35mVal steps: \u001b[36m188 \u001b[32m24.88s \u001b[35mg_loss:\u001b[94m 1.076671\u001b[35m d_loss:\u001b[94m 0.576716\u001b[35m val_g_loss:\u001b[94m 0.900082\u001b[35m val_d_loss:\u001b[94m 0.582782\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m19/20 \u001b[35mTrain steps: \u001b[36m750 \u001b[35mVal steps: \u001b[36m188 \u001b[32m24.85s \u001b[35mg_loss:\u001b[94m 1.053074\u001b[35m d_loss:\u001b[94m 0.583778\u001b[35m val_g_loss:\u001b[94m 0.996163\u001b[35m val_d_loss:\u001b[94m 0.579703\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m20/20 \u001b[35mTrain steps: \u001b[36m750 \u001b[35mVal steps: \u001b[36m188 \u001b[32m24.85s \u001b[35mg_loss:\u001b[94m 1.047826\u001b[35m d_loss:\u001b[94m 0.591432\u001b[35m val_g_loss:\u001b[94m 1.015650\u001b[35m val_d_loss:\u001b[94m 0.603477\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "_ = model.fit_generator(train_loader, valid_loader, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51e0fe95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mTest steps: \u001b[36m157 \u001b[32m2.28s \u001b[35mtest_g_loss:\u001b[94m 1.018641\u001b[35m test_d_loss:\u001b[94m 0.603591\u001b[0m                                                  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'time': 2.278034443035722,\n",
       " 'test_g_loss': 1.0186405668258667,\n",
       " 'test_d_loss': 0.6035914352416992}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = model.evaluate_generator(test_loader, return_dict_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52022e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mPrediction steps: \u001b[36m1 \u001b[32m0.02s \u001b[0m                                         \n"
     ]
    }
   ],
   "source": [
    "generator_model = Model(generator, None, None, device='cuda')\n",
    "\n",
    "# Choose the number of intermediate images that would be generated in\n",
    "# between the interpolation + 2 (start and last images).\n",
    "num_interpolation = 9  # @param {type:\"integer\"}\n",
    "\n",
    "# Sample noise for the interpolation.\n",
    "interpolation_noise = torch.randn((1, latent_dim))\n",
    "interpolation_noise = interpolation_noise.expand(num_interpolation, latent_dim)\n",
    "\n",
    "\n",
    "def interpolate_class(first_number, second_number):\n",
    "    first_label = F.one_hot(torch.tensor([first_number]), num_classes=num_classes).float()\n",
    "    second_label = F.one_hot(torch.tensor([second_number]), num_classes=num_classes).float()\n",
    "\n",
    "    # Calculate the interpolation vector between the two labels.\n",
    "    percent_second_label = torch.linspace(0, 1, num_interpolation)[:, None]\n",
    "    interpolation_labels = first_label * (1 - percent_second_label) + second_label * percent_second_label\n",
    "\n",
    "    # Combine the noise and the labels and run inference with the generator.\n",
    "    noise_and_labels = torch.cat((interpolation_noise, interpolation_labels), axis=1)\n",
    "    fake = generator_model.predict(noise_and_labels, convert_to_numpy=False).cpu()\n",
    "\n",
    "    return fake\n",
    "\n",
    "\n",
    "def get_gif(fake_images):\n",
    "    converted_images = 255.0 * fake_images\n",
    "    converted_images = F.interpolate(converted_images, (96, 96)).byte()\n",
    "    converted_images = converted_images.expand(-1, 3, -1, -1)\n",
    "    converted_images = torch.movedim(converted_images, 1, 3)\n",
    "    converted_images = converted_images.numpy()\n",
    "    return converted_images\n",
    "\n",
    "\n",
    "start_class = 1  # @param {type:\"slider\", min:0, max:9, step:1}\n",
    "end_class = 5  # @param {type:\"slider\", min:0, max:9, step:1}\n",
    "\n",
    "fake_images = interpolate_class(start_class, end_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a591c4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/gif": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gif_data = iio.imwrite(\"<bytes>\", get_gif(fake_images), format_hint=\".gif\", duration=100)\n",
    "from IPython.display import Image\n",
    "\n",
    "display(Image(data=gif_data, format='gif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf58bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
