{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poutyne's tips and tricks\n",
    "\n",
    "Poutyne also over a variety of tools for fine tuning the information generated during the training, such as a coloring of the training, a progress bar, multi-GPUs, user callbacks interface and a user naming interface for the metrics names. \n",
    "\n",
    "We will explore those tools using a different problems as the one presented in [Introduction to Pytorch and Poutyne](https://github.com/GRAAL-Research/poutyne/blob/master/examples/introduction_pytorch_poutyne.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the import\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import requests\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from poutyne.framework import Model, ModelCheckpoint, CSVLogger, Callback, Experiment\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "train_data = pickle.load(open(\"/home/despacitov3/Bureau/address/train.p\", \"rb\"))\n",
    "valid_data = pickle.load(open(\"/home/despacitov3/Bureau/address/valid.p\", \"rb\"))\n",
    "test_data = pickle.load(open(\"/home/despacitov3/Bureau/address/test.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "lr = 0.1\n",
    "\n",
    "cuda_device = 0\n",
    "device = torch.device(\"cuda:%d\" % cuda_device if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Recurent Neural Network (RNN)\n",
    "\n",
    "In this notebook, we train a RNN, or more precisely a LSTM, to predict the sequence of tag associated to a given address, know as parsing address.\n",
    "\n",
    "This task consist of detecting, by tagging, the different parts of an address such as the civic number, the street name or the postal code (or zip code). The following figure show an example of such a tagging.\n",
    "\n",
    "![address parsing canada](\"../docs/source/_static/img/address_parsing.png\")\n",
    "\n",
    "Since addresses are written in a predetermined sequence, RNN are the best way to crack this problem. For our architecture we will use two components, a RNN and a fully-connected layer.\n",
    "\n",
    "### RNN\n",
    "\n",
    "For the first components, instead of using a vanilla RNN, we will use a variant of it, know as a long short-term memory (LSTM) (to know more about [LSTM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/). For now, we will used a single layer unidirectionnal LSTM. \n",
    "\n",
    "Also, since our data is textual, we will use the well know word embeddings to encode the textual data. So our, LSTM input and hidden state dimensions will be the same size as the word embeddings dimension, which in our case will be the [French pre trained](https://fasttext.cc/docs/en/crawl-vectors.html) fastText embeddings of dimension 300. \n",
    "\n",
    "> See [here](https://discuss.pytorch.org/t/could-someone-explain-batch-first-true-in-lstm/15402) the explanation why we use the `batch_first` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 300\n",
    "num_layer = 1\n",
    "bidirectional = False\n",
    "\n",
    "lstm_network = nn.LSTM(input_size=dimension,\n",
    "                       hidden_size=dimension,\n",
    "                       num_layers=num_layer,\n",
    "                       bidirectional=bidirectional,\n",
    "                       batch_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-connected layer\n",
    "\n",
    "We use this layer to map the representation of the LSTM (300) to the tag space (8, the number of tags) and be able to predict the most likely tag using a softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = dimension #the output of the LSTM\n",
    "tag_dimension = 8\n",
    "\n",
    "fully_connected_network = nn.Linear(input_dim, tag_dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "Now let's take a look at the dataset, it is already splitted into a train, valid and test set using the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data from a directory\n",
    "\n",
    "#function to load the data from a repository\n",
    "def download_data(saving_dir, data_type):\n",
    "    root_url = \"https://rawcdn.githack.com/GRAAL-Research/poutyne-external-assets/d00ef70b1f44f5bc812c44d120c95bd411e882d6/tips_and_tricks_assets/{}.p\"\n",
    "\n",
    "    url = root_url.format(data_type)\n",
    "    r = requests.get(url)\n",
    "    os.makedirs(saving_dir, exist_ok=True)\n",
    "\n",
    "    open(os.path.join(saving_dir, f\"{data_type}.p\"), 'wb').write(r.content)\n",
    "    \n",
    "download_data('./data/', \"train\")\n",
    "download_data('./data/', \"valid\")\n",
    "download_data('./data/', \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "train_data = pickle.load(open(\"./data/train.p\", \"rb\"))  # 80,000 examples\n",
    "valid_data = pickle.load(open(\"./data/valid.p\", \"rb\"))  # 20,000 examples\n",
    "test_data = pickle.load(open(\"./data/test.p\", \"rb\"))  # 30,000 examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a look at the train dataset, it's a list of 80,000 tuples where the first element is the full address adn the second element is a list of the tag (the ground truth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('33 harnesworth crescent city of hamilton ontario l8b0j3',\n",
       "  ['StreetNumber',\n",
       "   'StreetName',\n",
       "   'StreetName',\n",
       "   'Municipality',\n",
       "   'Municipality',\n",
       "   'Municipality',\n",
       "   'Province',\n",
       "   'PostalCode']),\n",
       " ('1449 mouettes longueuil quebec j4j5k4',\n",
       "  ['StreetNumber', 'StreetName', 'Municipality', 'Province', 'PostalCode'])]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the address is a textual data, we need to _convert_ it into numerical value, such as word embeddings, for that we will use a vectorizer. This embedding vectorizer will be able to extract for every word a embedding value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-70-8ac02f78da2b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     19\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0membeddings\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 21\u001B[0;31m \u001B[0membedding_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mEmbeddingVectorizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m \u001B[0;31m# Sorry for the bad download templating the problem is on the side of fastText\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-70-8ac02f78da2b>\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m         \u001B[0mfasttext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutil\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdownload_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'fr'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mif_exists\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'ignore'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfasttext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"./cc.fr.300.bin\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maddress\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.7/site-packages/fasttext/FastText.py\u001B[0m in \u001B[0;36mload_model\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m    439\u001B[0m     \u001B[0;34m\"\"\"Load a model given a filepath and return a model object.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    440\u001B[0m     \u001B[0meprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 441\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_FastText\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    442\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    443\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.7/site-packages/fasttext/FastText.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, model_path, args)\u001B[0m\n\u001B[1;32m     96\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfasttext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfasttext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     97\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mmodel_path\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 98\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloadModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     99\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_words\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    100\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_labels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "class EmbeddingVectorizer:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Embedding vectorizer\n",
    "        \"\"\"\n",
    "\n",
    "        fasttext.util.download_model('fr', if_exists='ignore') \n",
    "        self.embedding_model = fasttext.load_model(\"./cc.fr.300.bin\")\n",
    "\n",
    "    def __call__(self, address):\n",
    "        \"\"\"\n",
    "        Convert address to embedding vectors\n",
    "        :param address: The address to convert\n",
    "        :return: The embeddings vectors\n",
    "        \"\"\"\n",
    "        embeddings = []\n",
    "        for word in address.split():\n",
    "            embeddings.append(self.embedding_model[word])\n",
    "        return embeddings\n",
    "     \n",
    "embedding_model = EmbeddingVectorizer() \n",
    "# Sorry for the bad download templating the problem is on the side of fastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a vectorizer for the to convert the address tag (StreeNumber, StreetName, ...) into numerical value. So we will use a Vectorizer class that can use the embedding vectorizer and also convert the address tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorizer:\n",
    "    def __init__(self, dataset, embedding_model):\n",
    "        self.data = dataset\n",
    "        self.embedding_model = embedding_model\n",
    "        self.tags_set = {\n",
    "            \"StreetNumber\": 0,\n",
    "            \"StreetName\": 1,\n",
    "            \"Unit\": 2,\n",
    "            \"Municipality\": 3,\n",
    "            \"Province\": 4,\n",
    "            \"PostalCode\": 5,\n",
    "            \"Orientation\": 6,\n",
    "            \"GeneralDelivery\": 7\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        data = self.data[item]\n",
    "        address = data[0]\n",
    "        address_vector = self.embedding_model(address)\n",
    "\n",
    "        tags = data[1]\n",
    "        idx_tags = self._convert_tags_to_idx(tags)\n",
    "\n",
    "        return address_vector, idx_tags\n",
    "\n",
    "    def _convert_tags_to_idx(self, tags):\n",
    "        idx_tags = []\n",
    "        for tag in tags:\n",
    "            idx_tags.append(self.tags_set[tag])\n",
    "        return idx_tags\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-72-2bef72c83c73>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrain_data_vectorize\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mVectorizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0membedding_model\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mvalid_data_vectorize\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mVectorizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalid_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0membedding_model\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mtest_data_vectorize\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mVectorizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0membedding_model\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'embedding_model' is not defined"
     ]
    }
   ],
   "source": [
    "train_data_vectorize = Vectorizer(train_data, embedding_model)\n",
    "valid_data_vectorize = Vectorizer(valid_data, embedding_model)\n",
    "test_data_vectorize = Vectorizer(test_data, embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "\n",
    "Now, since all the address are not of the same size, it is not possible to batch size them since all element of a tensor must have the same lengths. But there a trick, padding!\n",
    "\n",
    "The idea is simple, we will add _empty_ tokens at the ends of a sequence up to the longest one in a batch, and at the moment of evaluating the loss, that tokens will be skipped using a mask value. That way, we can pad and pack the sequence to minimize the training time ([here](https://stackoverflow.com/questions/51030782/why-do-we-pack-the-sequences-in-pytorch) an good explanation of why we pad and pack sequence).\n",
    "\n",
    "For that, we will use the `collate_fn` of the PyTorch DataLoader and on running time, that process will be done. We will create a class, that will save the padding value (usually zero) and the mask value (usually -100) and use the `__call__` method to process the batch elements.\n",
    "\n",
    "One time to take into account, since we have packed the sequence, we need the lengths of each individuals sequence for the forward pass to unpack them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadCollate:\n",
    "    \"\"\"\n",
    "        A variant of collate_fn that pads the sequence to the longest sequence in the minibatch.\n",
    "\n",
    "    **Args:**\n",
    "\n",
    "        :pad_idx (int): The padding idx to be use.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pad_idx: int = 0, mask_value: int = -100):\n",
    "        self.pad_idx = pad_idx\n",
    "        self.mask_value = mask_value\n",
    "\n",
    "    def _pad_collate_fn(self, batch):\n",
    "        \"\"\"\n",
    "        **Args:**\n",
    "\n",
    "            :batch - list of (List, List) where the first element of the tuple are the word idx and the second element\n",
    "            are the target label.\n",
    "\n",
    "        Returns:\n",
    "            A list of the padded tensor sequence idx and the padded label tensor of size of the longest sequence length.\n",
    "\n",
    "        \"\"\"\n",
    "        sequences_vectors, sequences_labels, lengths = zip(\n",
    "            *[(torch.FloatTensor(seq_vectors), torch.LongTensor(labels), len(seq_vectors)) for (seq_vectors, labels)\n",
    "              in sorted(batch, key=lambda x: len(x[0]), reverse=True)])\n",
    "\n",
    "        lengths = torch.LongTensor(lengths)\n",
    "\n",
    "        padded_sequences_vectors = pad_sequence(sequences_vectors, batch_first=True, padding_value=self.pad_idx)\n",
    "\n",
    "        padded_sequences_labels = pad_sequence(sequences_labels, batch_first=True, padding_value=self.pad_idx)\n",
    "\n",
    "        mask = self._mask_padding_sequences(lengths)\n",
    "        masked_target = torch.where(mask, padded_sequences_labels,\n",
    "                                    torch.ones_like(mask) * self.mask_value)\n",
    "\n",
    "        # We also pass the mask for the F1 score sine it need a mask tensor to be compute\n",
    "        return (padded_sequences_vectors, lengths), (masked_target, mask)\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        return self._pad_collate_fn(batch)\n",
    "\n",
    "    @staticmethod\n",
    "    def _mask_padding_sequences(lengths):\n",
    "        \"\"\"\n",
    "        Create a mask from the padding sequences lengths.\n",
    "    \n",
    "        Args:\n",
    "            lengths: The lengths use to create the padded sequence.\n",
    "        \"\"\"\n",
    "\n",
    "        max_len = lengths[0]\n",
    "        mask = torch.arange(max_len).expand(len(lengths), max_len) < lengths.unsqueeze(1)\n",
    "        return mask.bool()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data_vectorize, batch_size=batch_size, shuffle=True, collate_fn=PadCollate())\n",
    "valid_loader = DataLoader(valid_data_vectorize, batch_size=batch_size, collate_fn=PadCollate())\n",
    "test_loader = DataLoader(test_data_vectorize, batch_size=batch_size, collate_fn=PadCollate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Network\n",
    "\n",
    "Now, since we have packed the sequence, we are not able to used the PyTorch `nn.Sequential` constructor to define our model, so we will define the forward pass for it to unpack the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullNetWork(nn.Module):\n",
    "    def __init__(self, lstm_network, fully_connected_network):\n",
    "        super().__init__()\n",
    "        self.hidden_state = None\n",
    "        \n",
    "        self.lstm_network = lstm_network\n",
    "        self.fully_connected_network = fully_connected_network\n",
    "        \n",
    "    def forward(self, padded_sequences_vectors, lengths):\n",
    "        \"\"\"\n",
    "            Defines the computation performed at every call.\n",
    "        \"\"\"\n",
    "        pack_padded_sequences_vectors = pack_padded_sequence(padded_sequences_vectors, lengths, batch_first=True)\n",
    "\n",
    "        lstm_out, self.hidden_state = self.lstm_network(pack_padded_sequences_vectors)\n",
    "        lstm_out, _ = pad_packed_sequence(lstm_out, batch_first=True)\n",
    "\n",
    "        tag_space = self.fully_connected_network(lstm_out)\n",
    "        return tag_space.transpose(-1, 1) # we need to transpose since it's a sequence\n",
    "\n",
    "full_network = FullNetWork(lstm_network, fully_connected_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "So we have created a LSTM network (`lstm_network`) a fully connected network (`fully_connected_network`), those two components are use in the full network. This full network used padded packed sequences (defined in the forward pass) so we have created the `PadCollate` class to be able to process the need work. That process will be conducted by the DataLoader. Finally, when we will load the data, this will be done using the vectorizer so the address will be represented using word embeddings and the address components will be converted into categorical value (from 0 to 7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The training loop\n",
    "Now that we have all the components for the network, let's define our SGD optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(full_network.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poutyne Callbacks\n",
    "\n",
    "One nice feature of Poutyne is [callbacks](https://poutyne.org/callbacks.html). Callbacks allow to do actions during training of the neural network. In the following example, we use 3 callbacks. One that saves the latest weights in a file to be able to continue the optimization at the end of training if more epochs are needed. Another one that saves the best weights according to the performance on the validation dataset. Finally, another one that saves the displayed logs into a TSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "name_of_network = \"lstm_unidirectional\"\n",
    "\n",
    "callbacks = [\n",
    "        # Save the latest weights to be able to continue the optimization at the end for more epochs.\n",
    "        ModelCheckpoint(name_of_network + '_last_epoch.ckpt', temporary_filename='last_epoch.ckpt.tmp'),\n",
    "\n",
    "        # Save the weights in a new file when the current model is better than all previous models.\n",
    "        ModelCheckpoint(name_of_network + '_best_epoch_{epoch}.ckpt', monitor='val_acc', mode='max', save_best_only=True, restore_best=True, verbose=True, temporary_filename='best_epoch.ckpt.tmp'),\n",
    "\n",
    "        # Save the losses and accuracies for each epoch in a TSV.\n",
    "        CSVLogger(name_of_network + '_log.tsv', separator='\\t'),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Your Own Callback\n",
    "\n",
    "While Poutyne provides a great number of [predefined callbacks](https://poutyne.org/callbacks.html), it is sometimes useful to make your own callback.\n",
    "\n",
    "In the following example, we want to see the effect of temperature on the optimization of our neural network. To do so, we either increase or decrease the temperature during the optimization. As one can see in the result, temperature either as no effect or has detrimental effect on the performance of the neural network. This is so because the temperature has for effect to artificially changing the learning rates. Since we have found the right learning rate, increasing or decreasing it shows no improvement on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CrossEntropyLossWithTemperature(nn.Module):\n",
    "    \"\"\"\n",
    "    This loss module is the cross-entropy loss function\n",
    "    with temperature. It divides the logits by a temperature\n",
    "    value before computing the cross-entropy loss.\n",
    "\n",
    "    Args:\n",
    "        initial_temperature (float): The initial value of the temperature.\n",
    "    \"\"\"\n",
    "    def __init__(self, initial_temperature):\n",
    "        super().__init__()\n",
    "        self.temperature = initial_temperature\n",
    "        self.celoss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred = y_pred / self.temperature\n",
    "        return self.celoss(y_pred, y_true)\n",
    "\n",
    "class TemperatureCallback(Callback):\n",
    "    \"\"\"\n",
    "    This callback multiply the loss temperature with a decay before\n",
    "    each batch.\n",
    "\n",
    "    Args:\n",
    "        celoss_with_temp (CrossEntropyLossWithTemperature): the loss module.\n",
    "        decay (float): The value of the temperature decay.\n",
    "    \"\"\"\n",
    "    def __init__(self, celoss_with_temp, decay):\n",
    "        super().__init__()\n",
    "        self.celoss_with_temp = celoss_with_temp\n",
    "        self.decay = decay\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs):\n",
    "        self.celoss_with_temp.temperature *= self.decay\n",
    "\n",
    "def train_with_temperature(pytorch_network, initial_temperature, temperature_decay):\n",
    "    \"\"\"\n",
    "    In addition to the the `poutyne_train`, this function uses a cross-entropy loss\n",
    "    with temperature and decays the temperature at each batch.\n",
    "\n",
    "    Args:\n",
    "        pytorch_network (torch.nn.Module): The neural network to train.\n",
    "        initial_temperature (float): The initial value of the temperature.\n",
    "        decay (float): The value of the temperature decay.\n",
    "    \"\"\"\n",
    "    print(pytorch_network)\n",
    "    train_loader, valid_loader, test_loader = loaders\n",
    "    optimizer = optim.SGD(pytorch_network.parameters(), lr=learning_rate)\n",
    "\n",
    "    loss_function = CrossEntropyLossWithTemperature(initial_temperature)\n",
    "    callbacks = [TemperatureCallback(loss_function, temperature_decay)]\n",
    "    model = Model(pytorch_network, optimizer, loss_function, batch_metrics=['accuracy'])\n",
    "    model.to(device)\n",
    "    model.fit_generator(train_loader, valid_loader, epochs=num_epochs, callbacks=callbacks)\n",
    "    test_loss, test_acc = model.evaluate_generator(test_loader)\n",
    "    print('Test:\\n\\tLoss: {}\\n\\tAccuracy: {}'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our, loss functionn will be the cross entropy with temperature with a initial temperature of `0.1` and a temperature decay of `1.0008`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = CrossEntropyLossWithTemperature(0.1)\n",
    "callbacks = callbacks + [TemperatureCallback(loss_function, 1.0008)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test our training loop for one epoch using the accuracy as the batch metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-36-fee2eebfae8d>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfull_network\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_metrics\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'accuracy'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_generator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalid_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Github/poutyne/poutyne/framework/model.py\u001B[0m in \u001B[0;36mfit_generator\u001B[0;34m(self, train_generator, valid_generator, epochs, steps_per_epoch, validation_steps, batches_per_step, initial_epoch, verbose, coloring, progress_bar, callbacks)\u001B[0m\n\u001B[1;32m    421\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_fit_generator_n_batches_per_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch_iterator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallback_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatches_per_step\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    422\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 423\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_fit_generator_one_batch_per_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch_iterator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallback_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    424\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    425\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mepoch_iterator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mepoch_logs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Github/poutyne/poutyne/framework/model.py\u001B[0m in \u001B[0;36m_fit_generator_one_batch_per_step\u001B[0;34m(self, epoch_iterator, callback_list)\u001B[0m\n\u001B[1;32m    490\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mtrain_step_iterator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalid_step_iterator\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mepoch_iterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    491\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_set_training_mode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 492\u001B[0;31m                 \u001B[0;32mfor\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtrain_step_iterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    493\u001B[0m                     \u001B[0mstep\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmetrics\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_fit_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcallback_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumber\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    494\u001B[0m                     \u001B[0mstep\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_batch_size\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Github/poutyne/poutyne/framework/iterators.py\u001B[0m in \u001B[0;36m__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     60\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__iter__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     61\u001B[0m         \u001B[0mtime_since_last_batch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtimeit\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdefault_timer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 62\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;32min\u001B[0m \u001B[0m_get_step_iterator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msteps_per_epoch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgenerator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     63\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Github/poutyne/poutyne/framework/iterators.py\u001B[0m in \u001B[0;36mcycle\u001B[0;34m(iterable)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mcycle\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterable\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# Equivalent to itertools cycle, without any extra memory requirement\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0miterable\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     20\u001B[0m             \u001B[0;32myield\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    343\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    344\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__next__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 345\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    346\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    347\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    383\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    384\u001B[0m         \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 385\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    386\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    387\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     45\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 47\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcollate_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-17-c9c722164971>\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 43\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pad_collate_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     44\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     45\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-17-c9c722164971>\u001B[0m in \u001B[0;36m_pad_collate_fn\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m     25\u001B[0m         sequences_vectors, sequences_labels, lengths = zip(\n\u001B[1;32m     26\u001B[0m             *[(torch.FloatTensor(seq_vectors), torch.LongTensor(labels), len(seq_vectors)) for (seq_vectors, labels)\n\u001B[0;32m---> 27\u001B[0;31m               in sorted(batch, key=lambda x: len(x[0]), reverse=True)])\n\u001B[0m\u001B[1;32m     28\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m         \u001B[0mlengths\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLongTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlengths\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-17-c9c722164971>\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     24\u001B[0m         \"\"\"\n\u001B[1;32m     25\u001B[0m         sequences_vectors, sequences_labels, lengths = zip(\n\u001B[0;32m---> 26\u001B[0;31m             *[(torch.FloatTensor(seq_vectors), torch.LongTensor(labels), len(seq_vectors)) for (seq_vectors, labels)\n\u001B[0m\u001B[1;32m     27\u001B[0m               in sorted(batch, key=lambda x: len(x[0]), reverse=True)])\n\u001B[1;32m     28\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "model = Model(full_network, optimizer, loss_function, batch_metrics=['accuracy'])\n",
    "model.to(device)\n",
    "model.fit_generator(train_loader, valid_loader, epochs=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Also, Poutyne use by default a coloring template of the training step when the package `colorama` is installed.\n",
    "#One could either remove the coloring (`color_log=False`) or set a different coloring template using the fields:\n",
    "#`text_color`, `ratio_color`, `metric_value_color`, `time_color` and `progress_bar_color`.\n",
    "#If a field is not specified, the default color will be used.\n",
    "\n",
    "#Here an example where we set the `text_color` to MAGENTA and the `ratio_color` to BLUE.\n",
    "\n",
    "#```python\n",
    "#model.fit(\n",
    "#    train_x,\n",
    "#    train_y,\n",
    "#    validation_data=(valid_x, valid_y),\n",
    "#    epochs=5,\n",
    "#    coloring={\"text_color\": \"MAGENTA\", \"ratio_color\":\"BLUE\"})\n",
    "#```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate_generator(test_loader)\n",
    "print('Test:\\n\\tLoss: {}\\n\\tAccuracy: {}'.format(test_loss, test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}