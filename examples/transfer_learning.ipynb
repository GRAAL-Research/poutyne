{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "from shutil import copyfile\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from torch.utils import model_zoo\n",
    "\n",
    "from poutyne.framework import Model, ModelCheckpoint, BestModelRestore, CSVLogger\n",
    "from poutyne import torch_to_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract_dataset(path):\n",
    "    tgz_filename = \"images.tgz\"\n",
    "    urllib.request.urlretrieve(\"http://www.vision.caltech.edu/visipedia-data/CUB-200/images.tgz\", tgz_filename)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    archive = tarfile.open(tgz_filename)\n",
    "    archive.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy(source_path, filenames, dest_path):\n",
    "    for filename in filenames:\n",
    "        source = os.path.join(source_path, filename)\n",
    "        dest = os.path.join(dest_path, filename)\n",
    "        copyfile(source, dest)\n",
    "\n",
    "def split_train_valid_test(dataset_path, train_path, valid_path, test_path, train_split=0.6, valid_split=0.2): # test_split=0.2\n",
    "    np.random.seed(42)\n",
    "    for classname in sorted(os.listdir(dataset_path)):\n",
    "        if classname.startswith('.'):\n",
    "            continue\n",
    "        train_class_path = os.path.join(train_path, classname)\n",
    "        valid_class_path = os.path.join(valid_path, classname)\n",
    "        test_class_path = os.path.join(test_path, classname)\n",
    "\n",
    "        os.makedirs(train_class_path, exist_ok=True)\n",
    "        os.makedirs(valid_class_path, exist_ok=True)\n",
    "        os.makedirs(test_class_path, exist_ok=True)\n",
    "\n",
    "        dataset_class_path = os.path.join(dataset_path, classname)\n",
    "        filenames = sorted(filename for filename in os.listdir(dataset_class_path) if not filename.startswith('.'))\n",
    "        np.random.shuffle(filenames)\n",
    "\n",
    "        num_examples = len(filenames)\n",
    "        train_last_idx = math.ceil(num_examples*train_split)\n",
    "        valid_last_idx = train_last_idx + math.floor(num_examples*valid_split)\n",
    "        train_filenames = filenames[0:train_last_idx]\n",
    "        valid_filenames = filenames[train_last_idx:valid_last_idx]\n",
    "        test_filenames = filenames[valid_last_idx:]\n",
    "        copy(dataset_class_path, train_filenames, train_class_path)\n",
    "        copy(dataset_class_path, valid_filenames, valid_class_path)\n",
    "        copy(dataset_class_path, test_filenames, test_class_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do the split train/valid/test.\n",
    "\n",
    "base_path = './CUB200'\n",
    "dataset_path = os.path.join(base_path, 'images')\n",
    "train_path = os.path.join(base_path, 'train')\n",
    "valid_path = os.path.join(base_path, 'valid')\n",
    "test_path = os.path.join(base_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_extract_dataset(base_path)\n",
    "split_train_valid_test(dataset_path, train_path, valid_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = 0\n",
    "device = torch.device(\"cuda:%d\" % cuda_device if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "\n",
    "batch_size = 32\n",
    "learning_rate = 0.1\n",
    "n_epoch = 30\n",
    "num_classes = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6392e67290>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the PyTorch's datasets for our problem.\n",
    "\n",
    "norm_coefs = {}\n",
    "norm_coefs['cub200'] = [(0.47421962,  0.4914721 ,  0.42382449), (0.22846779,  0.22387765,  0.26495799)]\n",
    "norm_coefs['imagenet'] = [(0.485, 0.456, 0.406), (0.229, 0.224, 0.225)]\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*norm_coefs['cub200'])\n",
    "])\n",
    "\n",
    "train_set = ImageFolder(train_path, transform=transform)\n",
    "valid_set = ImageFolder(valid_path, transform=transform)\n",
    "test_set = ImageFolder(test_path, transform=transform)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loading a pretrained ResNet-18 networks and replacing \n",
    "# the head with the number of neurons equal to our number \n",
    "# of classes.\n",
    "\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We freeze the network except for its head.\n",
    "\n",
    "def freeze_weights(resnet18):\n",
    "    for name, param in resnet18.named_parameters():\n",
    "        if not name.startswith('fc.'):\n",
    "            param.requires_grad = False\n",
    "\n",
    "freeze_weights(resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One nice feature of Poutyne is callbacks.\n",
    "\n",
    "callbacks = [\n",
    "    # Save the latest weights to be able to continue the optimization at the end for more epochs.\n",
    "    ModelCheckpoint('last_epoch.ckpt', temporary_filename='last_epoch.ckpt.tmp'),\n",
    "    \n",
    "    # Save the weights in a new file when the current model is better than all previous models.\n",
    "    ModelCheckpoint('best_epoch_{epoch}.ckpt', monitor='val_acc', mode='max', save_best_only=True, restore_best=True, verbose=True, temporary_filename='best_epoch.ckpt.tmp'),\n",
    "    \n",
    "    # Save the losses and accuracies for each epoch in a TSV.\n",
    "    CSVLogger('log.tsv', separator='\\t'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 31.67s Step 116/116: loss: 4.738788, acc: 6.731549, val_loss: 3.886809, val_acc: 11.327434\n",
      "Epoch 1: val_acc improved from -inf to 11.32743, saving file to best_epoch_1.ckpt\n",
      "Epoch 2/30 31.39s Step 116/116: loss: 3.006773, acc: 33.144093, val_loss: 3.271729, val_acc: 21.592920\n",
      "Epoch 2: val_acc improved from 11.32743 to 21.59292, saving file to best_epoch_2.ckpt\n",
      "Epoch 3/30 31.48s Step 116/116: loss: 2.153980, acc: 52.771019, val_loss: 2.667525, val_acc: 35.752212\n",
      "Epoch 3: val_acc improved from 21.59292 to 35.75221, saving file to best_epoch_3.ckpt\n",
      "Epoch 4/30 31.77s Step 116/116: loss: 1.666963, acc: 64.909435, val_loss: 2.600248, val_acc: 36.106195\n",
      "Epoch 4: val_acc improved from 35.75221 to 36.10619, saving file to best_epoch_4.ckpt\n",
      "Epoch 5/30 31.62s Step 116/116: loss: 1.336615, acc: 73.019735, val_loss: 2.355025, val_acc: 41.327434\n",
      "Epoch 5: val_acc improved from 36.10619 to 41.32743, saving file to best_epoch_5.ckpt\n",
      "Epoch 6/30 31.49s Step 116/116: loss: 1.119106, acc: 79.264666, val_loss: 2.245564, val_acc: 43.628319\n",
      "Epoch 6: val_acc improved from 41.32743 to 43.62832, saving file to best_epoch_6.ckpt\n",
      "Epoch 7/30 31.24s Step 116/116: loss: 0.942244, acc: 83.941606, val_loss: 2.164859, val_acc: 44.955752\n",
      "Epoch 7: val_acc improved from 43.62832 to 44.95575, saving file to best_epoch_7.ckpt\n",
      "Epoch 8/30 30.55s Step 116/116: loss: 0.834597, acc: 86.563936, val_loss: 2.138340, val_acc: 46.460177\n",
      "Epoch 8: val_acc improved from 44.95575 to 46.46018, saving file to best_epoch_8.ckpt\n",
      "Epoch 9/30 29.96s Step 116/116: loss: 0.707844, acc: 89.943228, val_loss: 2.096751, val_acc: 47.256637\n",
      "Epoch 9: val_acc improved from 46.46018 to 47.25664, saving file to best_epoch_9.ckpt\n",
      "Epoch 10/30 30.13s Step 116/116: loss: 0.657364, acc: 90.456880, val_loss: 2.091874, val_acc: 48.407080\n",
      "Epoch 10: val_acc improved from 47.25664 to 48.40708, saving file to best_epoch_10.ckpt\n",
      "Epoch 11/30 30.37s Step 116/116: loss: 0.579423, acc: 92.944039, val_loss: 2.079854, val_acc: 47.964602\n",
      "Epoch 12/30 30.40s Step 116/116: loss: 0.518997, acc: 94.484996, val_loss: 2.053490, val_acc: 48.230088\n",
      "Epoch 13/30 30.84s Step 116/116: loss: 0.477968, acc: 95.647472, val_loss: 2.057845, val_acc: 48.938053\n",
      "Epoch 13: val_acc improved from 48.40708 to 48.93805, saving file to best_epoch_13.ckpt\n",
      "Epoch 14/30 31.16s Step 116/116: loss: 0.443343, acc: 95.728575, val_loss: 2.032495, val_acc: 48.672566\n",
      "Epoch 15/30 30.98s Step 116/116: loss: 0.407208, acc: 96.755880, val_loss: 2.042751, val_acc: 48.849558\n",
      "Epoch 16/30 30.25s Step 116/116: loss: 0.387245, acc: 97.296567, val_loss: 1.982231, val_acc: 51.150443\n",
      "Epoch 16: val_acc improved from 48.93805 to 51.15044, saving file to best_epoch_16.ckpt\n",
      "Epoch 17/30 30.41s Step 116/116: loss: 0.363878, acc: 97.350635, val_loss: 2.042369, val_acc: 48.584071\n",
      "Epoch 18/30 31.45s Step 116/116: loss: 0.346148, acc: 98.350906, val_loss: 2.014449, val_acc: 49.911504\n",
      "Epoch 19/30 31.77s Step 116/116: loss: 0.323372, acc: 98.621249, val_loss: 1.962966, val_acc: 51.681416\n",
      "Epoch 19: val_acc improved from 51.15044 to 51.68142, saving file to best_epoch_19.ckpt\n",
      "Epoch 20/30 30.13s Step 116/116: loss: 0.302575, acc: 98.459043, val_loss: 1.993863, val_acc: 50.707965\n",
      "Epoch 21/30 30.44s Step 116/116: loss: 0.295383, acc: 98.648283, val_loss: 2.003684, val_acc: 50.442478\n",
      "Epoch 22/30 30.34s Step 116/116: loss: 0.290717, acc: 98.594215, val_loss: 1.975835, val_acc: 50.707965\n",
      "Epoch 23/30 30.43s Step 116/116: loss: 0.271518, acc: 98.972695, val_loss: 1.972084, val_acc: 50.442478\n",
      "Epoch 24/30 30.82s Step 116/116: loss: 0.264984, acc: 99.270073, val_loss: 1.987788, val_acc: 49.557522\n",
      "Epoch 25/30 29.88s Step 116/116: loss: 0.247648, acc: 99.270073, val_loss: 1.996973, val_acc: 51.150442\n",
      "Epoch 26/30 30.40s Step 116/116: loss: 0.244376, acc: 99.297107, val_loss: 1.989042, val_acc: 50.884956\n",
      "Epoch 27/30 30.67s Step 116/116: loss: 0.239771, acc: 99.648554, val_loss: 2.000352, val_acc: 50.884956\n",
      "Epoch 28/30 30.68s Step 116/116: loss: 0.235576, acc: 99.378210, val_loss: 1.983018, val_acc: 50.088496\n",
      "Epoch 29/30 ETA 6s Step 87/116: loss: 0.249177, acc: 100.0000000"
     ]
    }
   ],
   "source": [
    "# Finally, we start the training and output its final test \n",
    "# loss and accuracy.\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = optim.SGD(resnet18.fc.parameters(), lr=learning_rate, weight_decay=0.001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Poutyne Model\n",
    "model = Model(resnet18, optimizer, loss_function, metrics=['accuracy'])\n",
    "\n",
    "# Send model on GPU\n",
    "model.to(device)\n",
    "\n",
    "# Train\n",
    "model.fit_generator(train_loader, valid_loader, epochs=n_epoch, callbacks=callbacks)\n",
    "\n",
    "# Test\n",
    "test_loss, test_acc = model.evaluate_generator(test_loader)\n",
    "print('Test:\\n\\tLoss: {}\\n\\tAccuracy: {}'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logs = pd.read_csv('log.tsv', sep='\\t')\n",
    "print(logs)\n",
    "\n",
    "best_epoch_idx = logs['val_acc'].idxmax()\n",
    "best_epoch = int(logs.loc[best_epoch_idx]['epoch'])\n",
    "print(\"Best epoch: %d\" % best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = ['loss', 'val_loss']\n",
    "plt.plot(logs['epoch'], logs[metrics])\n",
    "plt.legend(metrics)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['acc', 'val_acc']\n",
    "plt.plot(logs['epoch'], logs[metrics])\n",
    "plt.legend(metrics)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore best model from checkpoint and test it.\n",
    "\n",
    "resnet18 = models.resnet18(pretrained=False, num_classes=num_classes)\n",
    "\n",
    "model = Model(resnet18, 'sgd', 'cross_entropy', metrics=['accuracy'])\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model.load_weights('best_epoch_{epoch}.ckpt'.format(epoch=best_epoch))\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_loader)\n",
    "print('Test:\\n\\tLoss: {}\\n\\tAccuracy: {}'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
