

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Experiment and ModelBundle &mdash; Poutyne 1.17.3 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=a487ca7d"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Metrics" href="metrics.html" />
    <link rel="prev" title="Model" href="model.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html">
            
              <img src="_static/poutyne-light.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="model.html">Model</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Experiment and ModelBundle</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#experiment-function">Experiment function</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#poutyne.Experiment"><code class="docutils literal notranslate"><span class="pre">Experiment()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#modelbundle-class">ModelBundle class</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#poutyne.ModelBundle"><code class="docutils literal notranslate"><span class="pre">ModelBundle</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#poutyne.ModelBundle.from_network"><code class="docutils literal notranslate"><span class="pre">ModelBundle.from_network()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#poutyne.ModelBundle.from_model"><code class="docutils literal notranslate"><span class="pre">ModelBundle.from_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#poutyne.ModelBundle.get_path"><code class="docutils literal notranslate"><span class="pre">ModelBundle.get_path()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#poutyne.ModelBundle.get_best_epoch_stats"><code class="docutils literal notranslate"><span class="pre">ModelBundle.get_best_epoch_stats()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#poutyne.ModelBundle.get_saved_epochs"><code class="docutils literal notranslate"><span class="pre">ModelBundle.get_saved_epochs()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#poutyne.ModelBundle.train"><code class="docutils literal notranslate"><span class="pre">ModelBundle.train()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#poutyne.ModelBundle.train_dataset"><code class="docutils literal notranslate"><span class="pre">ModelBundle.train_dataset()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#poutyne.ModelBundle.train_data"><code class="docutils literal notranslate"><span class="pre">ModelBundle.train_data()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#poutyne.ModelBundle.load_checkpoint"><code class="docutils literal notranslate"><span class="pre">ModelBundle.load_checkpoint()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#poutyne.ModelBundle.test"><code class="docutils literal notranslate"><span class="pre">ModelBundle.test()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#poutyne.ModelBundle.test_dataset"><code class="docutils literal notranslate"><span class="pre">ModelBundle.test_dataset()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#poutyne.ModelBundle.test_data"><code class="docutils literal notranslate"><span class="pre">ModelBundle.test_data()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#poutyne.ModelBundle.infer"><code class="docutils literal notranslate"><span class="pre">ModelBundle.infer()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#poutyne.ModelBundle.infer_dataset"><code class="docutils literal notranslate"><span class="pre">ModelBundle.infer_dataset()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#poutyne.ModelBundle.infer_data"><code class="docutils literal notranslate"><span class="pre">ModelBundle.infer_data()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#poutyne.ModelBundle.is_better_than"><code class="docutils literal notranslate"><span class="pre">ModelBundle.is_better_than()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="callbacks.html">Callbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="layers.html">Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">Utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="examples/introduction.html">Introduction to PyTorch and Poutyne</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/tips_and_tricks.html">Tips and Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/sequence_tagging.html">Sequence Tagging With an RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/policy_interface.html">Interface of <code class="docutils literal notranslate"><span class="pre">policy</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/transfer_learning.html">Transfer learning example</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/image_reconstruction.html">Image Reconstruction Using Poutyne</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/classification_and_regression.html">Gender Classification and Eyes Location Detection: A Two Task Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/semantic_segmentation.html">Semantic segmentation using Poutyne</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Poutyne</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Experiment and ModelBundle</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/experiment.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="experiment-and-modelbundle">
<h1>Experiment and ModelBundle<a class="headerlink" href="#experiment-and-modelbundle" title="Link to this heading"></a></h1>
<section id="experiment-function">
<h2>Experiment function<a class="headerlink" href="#experiment-function" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="poutyne.Experiment">
<span class="sig-prename descclassname"><span class="pre">poutyne.</span></span><span class="sig-name descname"><span class="pre">Experiment</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#poutyne.Experiment" title="Link to this definition"></a></dt>
<dd><p>Alias of <a class="reference internal" href="#poutyne.ModelBundle.from_network" title="poutyne.ModelBundle.from_network"><code class="xref py py-func docutils literal notranslate"><span class="pre">ModelBundle.from_network()</span></code></a>.</p>
</dd></dl>

</section>
<section id="modelbundle-class">
<h2>ModelBundle class<a class="headerlink" href="#modelbundle-class" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="poutyne.ModelBundle">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">poutyne.</span></span><span class="sig-name descname"><span class="pre">ModelBundle</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">directory</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="model.html#poutyne.Model" title="poutyne.framework.model.Model"><span class="pre">Model</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logging</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitoring</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitor_metric</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitor_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_is_direct</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/poutyne/framework/model_bundle.html#ModelBundle"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#poutyne.ModelBundle" title="Link to this definition"></a></dt>
<dd><p>The <a class="reference internal" href="#poutyne.ModelBundle" title="poutyne.ModelBundle"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelBundle</span></code></a> class provides a straightforward experimentation tool for efficient and entirely
customizable finetuning of the whole neural network training procedure with PyTorch. The
<a class="reference internal" href="#poutyne.ModelBundle" title="poutyne.ModelBundle"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelBundle</span></code></a> object takes care of the training and testing processes while also managing to keep
traces of all pertinent information via the automatic logging option.</p>
<p>Use <code class="docutils literal notranslate"><span class="pre">ModelBundle.from_*</span></code> methods to instanciate a <a class="reference internal" href="#poutyne.ModelBundle" title="poutyne.ModelBundle"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelBundle</span></code></a>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="poutyne.ModelBundle.from_network">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_network</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">directory</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">network</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.5)"><span class="pre">Module</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.5)"><span class="pre">device</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.5)"><span class="pre">device</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logging</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.5)"><span class="pre">Optimizer</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sgd'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_function</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.13)"><span class="pre">Callable</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_metrics</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch_metrics</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitoring</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitor_metric</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitor_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/poutyne/framework/model_bundle.html#ModelBundle.from_network"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#poutyne.ModelBundle.from_network" title="Link to this definition"></a></dt>
<dd><p>Instanciate a <a class="reference internal" href="#poutyne.ModelBundle" title="poutyne.ModelBundle"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelBundle</span></code></a> from a PyTorch <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.5)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>directory</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Path to the model bundle’s working directory. Will be used for automatic logging.</p></li>
<li><p><strong>network</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.5)"><em>torch.nn.Module</em></a>) – A PyTorch network.</p></li>
<li><p><strong>device</strong> (<em>Union</em><em>[</em><em>torch.torch.device</em><em>, </em><em>List</em><em>[</em><em>torch.torch.device</em><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>None</em><em>]</em>) – The device to which the model is
sent or for multi-GPUs, the list of devices to which the model is to be sent. When using a string for a
multiple GPUs, the option is “all”, for “take them all.” By default, the current device is used as the
main one. If None, the model will be kept on its current device.
(Default value = None)</p></li>
<li><p><strong>logging</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether or not to log the model bundle’s progress. If true, various logging
callbacks will be inserted to output training and testing stats as well as to save model checkpoints,
for example, automatically. See <a class="reference internal" href="#poutyne.ModelBundle.train" title="poutyne.ModelBundle.train"><code class="xref py py-func docutils literal notranslate"><span class="pre">train()</span></code></a> and <a class="reference internal" href="#poutyne.ModelBundle.test" title="poutyne.ModelBundle.test"><code class="xref py py-func docutils literal notranslate"><span class="pre">test()</span></code></a> for more
details. (Default value = True)</p></li>
<li><p><strong>optimizer</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.5)"><em>torch.optim.Optimizer</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – If Pytorch Optimizer, must already be initialized.
If str, should be the optimizer’s name in Pytorch (i.e. ‘Adam’ for torch.optim.Adam).
(Default value = ‘sgd’)</p></li>
<li><p><strong>loss_function</strong> (<em>Union</em><em>[</em><em>Callable</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>, </em><em>optional</em>) – loss layer or custom loss function. It can also be a string with the same name as a PyTorch
loss function (either the functional or object name). The loss function must have the signature
<code class="docutils literal notranslate"><span class="pre">loss_function(input,</span> <span class="pre">target)</span></code> where <code class="docutils literal notranslate"><span class="pre">input</span></code> is the prediction of the network and <code class="docutils literal notranslate"><span class="pre">target</span></code>
is the ground truth. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, will default to, in priority order, either the model’s own
loss function or the default loss function associated with the <code class="docutils literal notranslate"><span class="pre">task</span></code>.
(Default value = None)</p></li>
<li><p><strong>batch_metrics</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a>) – <p>List of functions with the same signature as a loss function or objects with the same
signature as either <a class="reference internal" href="metrics.html#poutyne.Metric" title="poutyne.Metric"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code></a> or <a class="reference external" href="https://lightning.ai/docs/torchmetrics/latest/references/metric.html#torchmetrics.Metric" title="(in PyTorch-Metrics v1.7.0dev)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchmetrics.Metric</span></code></a>. It can
also be a string with the same name as a PyTorch loss function (either the functional or object name).
Some metrics, such as  ‘accuracy’ (or just ‘acc’), are also available as strings. See <a class="reference internal" href="metrics.html#metrics"><span class="std std-ref">Metrics</span></a> and
the <a class="reference external" href="https://torchmetrics.readthedocs.io/en/latest/references/modules.html">TorchMetrics documentation</a>
for available metrics.</p>
<p>Batch metric are computed on computed for each batch.
(Default value = None)</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When using this argument, the metrics are computed for each batch. This can significantly slow
down the compuations depending on the metrics used. This mostly happens on non-decomposable metrics
such as <a class="reference external" href="https://lightning.ai/docs/torchmetrics/latest/classification/auroc.html#torchmetrics.AUROC" title="(in PyTorch-Metrics v1.7.0dev)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchmetrics.AUROC</span></code></a> where an ordering of the elements is necessary
to compute the metric. In such case, we advise to use them as epoch metrics instead.</p>
</div>
</p></li>
<li><p><strong>epoch_metrics</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a>) – <p>List of functions with the same signature as a loss function or objects with the same
signature as either <a class="reference internal" href="metrics.html#poutyne.Metric" title="poutyne.Metric"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code></a> or <a class="reference external" href="https://lightning.ai/docs/torchmetrics/latest/references/metric.html#torchmetrics.Metric" title="(in PyTorch-Metrics v1.7.0dev)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchmetrics.Metric</span></code></a>. It can
also be a string with the same name as a PyTorch loss function (either the functional or object name).
Some metrics, such as  ‘accuracy’ (or just ‘acc’), are also available as strings. See <a class="reference internal" href="metrics.html#metrics"><span class="std std-ref">Metrics</span></a> and
the <a class="reference external" href="https://torchmetrics.readthedocs.io/en/latest/references/modules.html">TorchMetrics documentation</a>
for available metrics.</p>
<p>Epoch metrics are computed only at the end of the epoch.
(Default value = None)</p>
</p></li>
<li><p><strong>monitoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether or not to monitor the training. If True will track the best epoch.
If False, <code class="docutils literal notranslate"><span class="pre">monitor_metric</span></code> and <code class="docutils literal notranslate"><span class="pre">monitor_mode</span></code> are not used, and when testing, the last epoch is used
to test the model instead of the best epoch.
(Default value = True)</p></li>
<li><p><strong>monitor_metric</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – <p>Which metric to consider for best model performance calculation. Should be
in the format ‘{metric_name}’ or ‘val_{metric_name}’ (i.e. ‘val_loss’). If None, will follow the value
suggested by <code class="docutils literal notranslate"><span class="pre">task</span></code> or default to ‘val_loss’. If <code class="docutils literal notranslate"><span class="pre">monitoring</span></code> is set to False, will be ignore.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If you do not plan on using a validation set, you must set the monitor metric to another
value.</p>
</div>
</p></li>
<li><p><strong>monitor_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Which mode, either ‘min’ or ‘max’, should be used when considering the
<code class="docutils literal notranslate"><span class="pre">monitor_metric</span></code> value. If None, will follow the value suggested by <code class="docutils literal notranslate"><span class="pre">task</span></code> or default to ‘min’.
If <code class="docutils literal notranslate"><span class="pre">monitoring</span></code> is set to False, will be ignore.</p></li>
<li><p><strong>task</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Any str beginning with either ‘classif’ or ‘reg’. Specifying a <code class="docutils literal notranslate"><span class="pre">task</span></code>
can assign default values to the <code class="docutils literal notranslate"><span class="pre">loss_function</span></code>, <code class="docutils literal notranslate"><span class="pre">batch_metrics</span></code>, <code class="docutils literal notranslate"><span class="pre">monitor_mode</span></code> and
<code class="docutils literal notranslate"><span class="pre">monitor_mode</span></code>. For <code class="docutils literal notranslate"><span class="pre">task</span></code> that begins with ‘reg’, the only default value is the loss function
that is the mean squared error. When beginning with ‘classif’, the default loss function is the
cross-entropy loss. The default batch metrics will be the accuracy, the default epoch metrics will be
the F1 score and the default monitoring will be set on ‘val_acc’ with a ‘max’ mode.
(Default value = None)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Using a PyTorch DataLoader, on classification task with SGD optimizer:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>
<span class="kn">from</span> <span class="nn">poutyne</span> <span class="kn">import</span> <span class="n">ModelBundle</span>

<span class="n">num_features</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># Our training dataset with 800 samples.</span>
<span class="n">num_train_samples</span> <span class="o">=</span> <span class="mi">800</span>
<span class="n">train_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_train_samples</span><span class="p">,</span> <span class="n">num_features</span><span class="p">)</span>
<span class="n">train_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="p">(</span><span class="n">num_train_samples</span><span class="p">,</span> <span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
<span class="n">train_generator</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

<span class="c1"># Our validation dataset with 200 samples.</span>
<span class="n">num_valid_samples</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">valid_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_valid_samples</span><span class="p">,</span> <span class="n">num_features</span><span class="p">)</span>
<span class="n">valid_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="p">(</span><span class="n">num_valid_samples</span><span class="p">,</span> <span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">valid_x</span><span class="p">,</span> <span class="n">valid_y</span><span class="p">)</span>
<span class="n">valid_generator</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

<span class="c1"># Our network</span>
<span class="n">pytorch_network</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_features</span><span class="p">,</span> <span class="n">num_train_samples</span><span class="p">)</span>

<span class="c1"># Initialization of our experimentation and network training</span>
<span class="n">exp</span> <span class="o">=</span> <span class="n">ModelBundle</span><span class="o">.</span><span class="n">from_network</span><span class="p">(</span><span class="s1">&#39;./simple_example&#39;</span><span class="p">,</span>
                               <span class="n">pytorch_network</span><span class="p">,</span>
                               <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;sgd&#39;</span><span class="p">,</span>
                               <span class="n">task</span><span class="o">=</span><span class="s1">&#39;classif&#39;</span><span class="p">)</span>
<span class="n">exp</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_generator</span><span class="p">,</span> <span class="n">valid_generator</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<p>The above code will yield an output similar to the below lines. Note the automatic checkpoint saving
in the model bundle directory when the monitored metric improved.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Epoch 1/5 0.09s Step 25/25: loss: 6.351375, acc: 1.375000, val_loss: 6.236106, val_acc: 5.000000
Epoch 1: val_acc improved from -inf to 5.00000, saving file to ./simple_example/checkpoint_epoch_1.ckpt
Epoch 2/5 0.10s Step 25/25: loss: 6.054254, acc: 14.000000, val_loss: 5.944495, val_acc: 19.500000
Epoch 2: val_acc improved from 5.00000 to 19.50000, saving file to ./simple_example/checkpoint_epoch_2.ckpt
Epoch 3/5 0.09s Step 25/25: loss: 5.759377, acc: 22.875000, val_loss: 5.655412, val_acc: 21.000000
Epoch 3: val_acc improved from 19.50000 to 21.00000, saving file to ./simple_example/checkpoint_epoch_3.ckpt
...
</pre></div>
</div>
<p>Training can now easily be resumed from the best checkpoint:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_generator</span><span class="p">,</span> <span class="n">valid_generator</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Restoring model from ./simple_example/checkpoint_epoch_3.ckpt
Loading weights from ./simple_example/checkpoint.ckpt and starting at epoch 6.
Loading optimizer state from ./simple_example/checkpoint.optim and starting at epoch 6.
Epoch 6/10 0.16s Step 25/25: loss: 4.897135, acc: 22.875000, val_loss: 4.813141, val_acc: 20.500000
Epoch 7/10 0.10s Step 25/25: loss: 4.621514, acc: 22.625000, val_loss: 4.545359, val_acc: 20.500000
Epoch 8/10 0.24s Step 25/25: loss: 4.354721, acc: 23.625000, val_loss: 4.287117, val_acc: 20.500000
...
</pre></div>
</div>
<p>Testing is also very intuitive:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">test_generator</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Restoring model from ./simple_example/checkpoint_epoch_9.ckpt
Found best checkpoint at epoch: 9
lr: 0.01, loss: 4.09892, acc: 23.625, val_loss: 4.04057, val_acc: 21.5
On best model: test_loss: 4.06664, test_acc: 17.5
</pre></div>
</div>
<p>Finally, all the pertinent metrics specified to the ModelBundle at each epoch are stored in a specific logging
file, found here at ‘./simple_example/log.tsv’.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>epoch   time                lr      loss                    acc     val_loss            val_acc
1           0.0721172170015052  0.01    6.351375141143799       1.375   6.23610631942749        5.0
2           0.0298177790245972  0.01    6.054253826141357       14.000  5.94449516296386        19.5
3           0.0637106419890187  0.01    5.759376544952392       22.875  5.65541223526001        21.0
...
</pre></div>
</div>
<p>Also, we could use more than one GPU (on a single node) by using the device argument</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># Initialization of our experimentation and network training
exp = ModelBundle.from_network(&#39;./simple_example&#39;,
                               pytorch_network,
                               optimizer=&#39;sgd&#39;,
                               task=&#39;classif&#39;,
                               device=&quot;all&quot;)
exp.train(train_generator, valid_generator, epochs=5)
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="poutyne.ModelBundle.from_model">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">directory</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="model.html#poutyne.Model" title="poutyne.framework.model.Model"><span class="pre">Model</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logging</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitoring</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitor_metric</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitor_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/poutyne/framework/model_bundle.html#ModelBundle.from_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#poutyne.ModelBundle.from_model" title="Link to this definition"></a></dt>
<dd><p>Instanciate a <a class="reference internal" href="#poutyne.ModelBundle" title="poutyne.ModelBundle"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelBundle</span></code></a> from a <a class="reference internal" href="model.html#poutyne.Model" title="poutyne.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code></a> instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>directory</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Path to the model bundle’s working directory. Will be used for automatic logging.</p></li>
<li><p><strong>model</strong> (<a class="reference internal" href="model.html#poutyne.Model" title="poutyne.Model"><em>poutyne.Model</em></a>) – A Model instance..</p></li>
<li><p><strong>logging</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether or not to log the model bundle’s progress. If true, various logging
callbacks will be inserted to output training and testing stats as well as to save model checkpoints,
for example, automatically. See <a class="reference internal" href="#poutyne.ModelBundle.train" title="poutyne.ModelBundle.train"><code class="xref py py-func docutils literal notranslate"><span class="pre">train()</span></code></a> and <a class="reference internal" href="#poutyne.ModelBundle.test" title="poutyne.ModelBundle.test"><code class="xref py py-func docutils literal notranslate"><span class="pre">test()</span></code></a> for more
details. (Default value = True)</p></li>
<li><p><strong>monitoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether or not to monitor the training. If True will track the best epoch.
If False, <code class="docutils literal notranslate"><span class="pre">monitor_metric</span></code> and <code class="docutils literal notranslate"><span class="pre">monitor_mode</span></code> are not used, and when testing, the last epoch is used
to test the model instead of the best epoch.
(Default value = True)</p></li>
<li><p><strong>monitor_metric</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – <p>Which metric to consider for best model performance calculation. Should be
in the format ‘{metric_name}’ or ‘val_{metric_name}’ (i.e. ‘val_loss’). If None, will follow the value
suggested by <code class="docutils literal notranslate"><span class="pre">task</span></code> or default to ‘val_loss’. If <code class="docutils literal notranslate"><span class="pre">monitoring</span></code> is set to False, will be ignore.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If you do not plan on using a validation set, you must set the monitor metric to another
value.</p>
</div>
</p></li>
<li><p><strong>monitor_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Which mode, either ‘min’ or ‘max’, should be used when considering the
<code class="docutils literal notranslate"><span class="pre">monitor_metric</span></code> value. If None, will follow the value suggested by <code class="docutils literal notranslate"><span class="pre">task</span></code> or default to ‘min’.
If <code class="docutils literal notranslate"><span class="pre">monitoring</span></code> is set to False, will be ignore.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Using a PyTorch DataLoader, on classification task with SGD optimizer:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>
<span class="kn">from</span> <span class="nn">poutyne</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">ModelBundle</span>

<span class="n">num_features</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># Our training dataset with 800 samples.</span>
<span class="n">num_train_samples</span> <span class="o">=</span> <span class="mi">800</span>
<span class="n">train_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_train_samples</span><span class="p">,</span> <span class="n">num_features</span><span class="p">)</span>
<span class="n">train_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="p">(</span><span class="n">num_train_samples</span><span class="p">,</span> <span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
<span class="n">train_generator</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

<span class="c1"># Our validation dataset with 200 samples.</span>
<span class="n">num_valid_samples</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">valid_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_valid_samples</span><span class="p">,</span> <span class="n">num_features</span><span class="p">)</span>
<span class="n">valid_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="p">(</span><span class="n">num_valid_samples</span><span class="p">,</span> <span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">valid_x</span><span class="p">,</span> <span class="n">valid_y</span><span class="p">)</span>
<span class="n">valid_generator</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

<span class="c1"># Our network</span>
<span class="n">pytorch_network</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_features</span><span class="p">,</span> <span class="n">num_train_samples</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">pytorch_network</span><span class="p">,</span> <span class="s1">&#39;sgd&#39;</span><span class="p">,</span> <span class="s1">&#39;crossentropy&#39;</span><span class="p">,</span> <span class="n">batch_metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># Initialization of our experimentation and network training</span>
<span class="n">exp</span> <span class="o">=</span> <span class="n">ModelBundle</span><span class="o">.</span><span class="n">from_model</span><span class="p">(</span><span class="s1">&#39;./simple_example&#39;</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="n">exp</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_generator</span><span class="p">,</span> <span class="n">valid_generator</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<p>The above code will yield an output similar to the below lines. Note the automatic checkpoint saving
in the model bundle directory when the monitored metric improved.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Epoch 1/5 0.09s Step 25/25: loss: 6.351375, acc: 1.375000, val_loss: 6.236106, val_acc: 5.000000
Epoch 1: val_acc improved from -inf to 5.00000, saving file to ./simple_example/checkpoint_epoch_1.ckpt
Epoch 2/5 0.10s Step 25/25: loss: 6.054254, acc: 14.000000, val_loss: 5.944495, val_acc: 19.500000
Epoch 2: val_acc improved from 5.00000 to 19.50000, saving file to ./simple_example/checkpoint_epoch_2.ckpt
Epoch 3/5 0.09s Step 25/25: loss: 5.759377, acc: 22.875000, val_loss: 5.655412, val_acc: 21.000000
Epoch 3: val_acc improved from 19.50000 to 21.00000, saving file to ./simple_example/checkpoint_epoch_3.ckpt
...
</pre></div>
</div>
<p>Training can now easily be resumed from the best checkpoint:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_generator</span><span class="p">,</span> <span class="n">valid_generator</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Restoring model from ./simple_example/checkpoint_epoch_3.ckpt
Loading weights from ./simple_example/checkpoint.ckpt and starting at epoch 6.
Loading optimizer state from ./simple_example/checkpoint.optim and starting at epoch 6.
Epoch 6/10 0.16s Step 25/25: loss: 4.897135, acc: 22.875000, val_loss: 4.813141, val_acc: 20.500000
Epoch 7/10 0.10s Step 25/25: loss: 4.621514, acc: 22.625000, val_loss: 4.545359, val_acc: 20.500000
Epoch 8/10 0.24s Step 25/25: loss: 4.354721, acc: 23.625000, val_loss: 4.287117, val_acc: 20.500000
...
</pre></div>
</div>
<p>Testing is also very intuitive:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">test_generator</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Restoring model from ./simple_example/checkpoint_epoch_9.ckpt
Found best checkpoint at epoch: 9
lr: 0.01, loss: 4.09892, acc: 23.625, val_loss: 4.04057, val_acc: 21.5
On best model: test_loss: 4.06664, test_acc: 17.5
</pre></div>
</div>
<p>Finally, all the pertinent metrics specified to the ModelBundle at each epoch are stored in a specific logging
file, found here at ‘./simple_example/log.tsv’.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>epoch   time                lr      loss                    acc     val_loss            val_acc
1           0.0721172170015052  0.01    6.351375141143799       1.375   6.23610631942749        5.0
2           0.0298177790245972  0.01    6.054253826141357       14.000  5.94449516296386        19.5
3           0.0637106419890187  0.01    5.759376544952392       22.875  5.65541223526001        21.0
...
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="poutyne.ModelBundle.get_path">
<span class="sig-name descname"><span class="pre">get_path</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">paths</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></span><a class="reference internal" href="_modules/poutyne/framework/model_bundle.html#ModelBundle.get_path"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#poutyne.ModelBundle.get_path" title="Link to this definition"></a></dt>
<dd><p>Returns the path inside the model bundle directory.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="poutyne.ModelBundle.get_best_epoch_stats">
<span class="sig-name descname"><span class="pre">get_best_epoch_stats</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a></span></span><a class="reference internal" href="_modules/poutyne/framework/model_bundle.html#ModelBundle.get_best_epoch_stats"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#poutyne.ModelBundle.get_best_epoch_stats" title="Link to this definition"></a></dt>
<dd><p>Returns all computed statistics corresponding to the best epoch according to the
<code class="docutils literal notranslate"><span class="pre">monitor_metric</span></code> and <code class="docutils literal notranslate"><span class="pre">monitor_mode</span></code> attributes.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict where each key is a column name in the logging output file
and values are the ones found at the best epoch.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="poutyne.ModelBundle.get_saved_epochs">
<span class="sig-name descname"><span class="pre">get_saved_epochs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/poutyne/framework/model_bundle.html#ModelBundle.get_saved_epochs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#poutyne.ModelBundle.get_saved_epochs" title="Link to this definition"></a></dt>
<dd><p>Returns a pandas DataFrame which each row corresponds to an epoch having
a saved checkpoint.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>pandas DataFrame which each row corresponds to an epoch having a saved
checkpoint.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="poutyne.ModelBundle.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_generator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_generator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/poutyne/framework/model_bundle.html#ModelBundle.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#poutyne.ModelBundle.train" title="Link to this definition"></a></dt>
<dd><p>Trains or finetunes the model on a dataset using a generator. If a previous training already occurred
and lasted a total of <cite>n_previous</cite> epochs, then the model’s weights will be set to the last checkpoint and the
training will be resumed for epochs range (<cite>n_previous</cite>, <cite>epochs</cite>].</p>
<p>If the ModelBundle has logging enabled (i.e. self.logging is True), numerous callbacks will be automatically
included. Notably, two <a class="reference internal" href="callbacks.html#poutyne.ModelCheckpoint" title="poutyne.ModelCheckpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code></a> objects will take care of saving the last and every
new best (according to monitor mode) model weights in appropriate checkpoint files.
<a class="reference internal" href="callbacks.html#poutyne.OptimizerCheckpoint" title="poutyne.OptimizerCheckpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">OptimizerCheckpoint</span></code></a> and <a class="reference internal" href="callbacks.html#poutyne.LRSchedulerCheckpoint" title="poutyne.LRSchedulerCheckpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">LRSchedulerCheckpoint</span></code></a> will also respectively
handle the saving of the optimizer and LR scheduler’s respective states for future retrieval. Moreover, a
<a class="reference internal" href="callbacks.html#poutyne.AtomicCSVLogger" title="poutyne.AtomicCSVLogger"><code class="xref py py-class docutils literal notranslate"><span class="pre">AtomicCSVLogger</span></code></a> will save all available epoch statistics in an output .tsv file. Lastly, a
<a class="reference internal" href="callbacks.html#poutyne.TensorBoardLogger" title="poutyne.TensorBoardLogger"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorBoardLogger</span></code></a> handles automatic TensorBoard logging of various neural network
statistics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_generator</strong> – Generator-like object for the training set. See <a class="reference internal" href="model.html#poutyne.Model.fit_generator" title="poutyne.Model.fit_generator"><code class="xref py py-func docutils literal notranslate"><span class="pre">fit_generator()</span></code></a>
for details on the types of generators supported.</p></li>
<li><p><strong>valid_generator</strong> (<em>optional</em>) – Generator-like object for the validation set. See
<a class="reference internal" href="model.html#poutyne.Model.fit_generator" title="poutyne.Model.fit_generator"><code class="xref py py-func docutils literal notranslate"><span class="pre">fit_generator()</span></code></a> for details on the types of generators supported.
(Default value = None)</p></li>
<li><p><strong>callbacks</strong> (<em>List</em><em>[</em><a class="reference internal" href="callbacks.html#poutyne.Callback" title="poutyne.Callback"><em>Callback</em></a><em>]</em>) – List of callbacks that will be called during
training. These callbacks are added after those used in this method (see above). This allows to assume
that they are called after those.
(Default value = None)</p></li>
<li><p><strong>lr_schedulers</strong> – List of learning rate schedulers. (Default value = None)</p></li>
<li><p><strong>keep_only_last_best</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether only the last saved best checkpoint is kept. Applies only when
<cite>save_every_epoch</cite> is false.
(Default value = False)</p></li>
<li><p><strong>save_every_epoch</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether or not to save the model bundle’s model’s weights after
every epoch.
(Default value = False)</p></li>
<li><p><strong>disable_tensorboard</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether or not to disable the automatic tensorboard logging
callbacks.
(Default value = False)</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Seed used to make the sampling deterministic.
(Default value = 42)</p></li>
<li><p><strong>kwargs</strong> – Any keyword arguments to pass to <a class="reference internal" href="model.html#poutyne.Model.fit_generator" title="poutyne.Model.fit_generator"><code class="xref py py-func docutils literal notranslate"><span class="pre">fit_generator()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of dict containing the history of each epoch.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="poutyne.ModelBundle.train_dataset">
<span class="sig-name descname"><span class="pre">train_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/poutyne/framework/model_bundle.html#ModelBundle.train_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#poutyne.ModelBundle.train_dataset" title="Link to this definition"></a></dt>
<dd><p>Trains or finetunes the model on a dataset. If a previous training already occurred
and lasted a total of <cite>n_previous</cite> epochs, then the model’s weights will be set to the last checkpoint and the
training will be resumed for epochs range (<cite>n_previous</cite>, <cite>epochs</cite>].</p>
<p>If the ModelBundle has logging enabled (i.e. self.logging is True), numerous callbacks will be automatically
included. Notably, two <a class="reference internal" href="callbacks.html#poutyne.ModelCheckpoint" title="poutyne.ModelCheckpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code></a> objects will take care of saving the last and every
new best (according to monitor mode) model weights in appropriate checkpoint files.
<a class="reference internal" href="callbacks.html#poutyne.OptimizerCheckpoint" title="poutyne.OptimizerCheckpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">OptimizerCheckpoint</span></code></a> and <a class="reference internal" href="callbacks.html#poutyne.LRSchedulerCheckpoint" title="poutyne.LRSchedulerCheckpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">LRSchedulerCheckpoint</span></code></a> will also respectively
handle the saving of the optimizer and LR scheduler’s respective states for future retrieval. Moreover, a
<a class="reference internal" href="callbacks.html#poutyne.AtomicCSVLogger" title="poutyne.AtomicCSVLogger"><code class="xref py py-class docutils literal notranslate"><span class="pre">AtomicCSVLogger</span></code></a> will save all available epoch statistics in an output .tsv file. Lastly, a
<a class="reference internal" href="callbacks.html#poutyne.TensorBoardLogger" title="poutyne.TensorBoardLogger"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorBoardLogger</span></code></a> handles automatic TensorBoard logging of various neural network
statistics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset" title="(in PyTorch v2.5)"><em>Dataset</em></a>) – Training dataset.</p></li>
<li><p><strong>valid_dataset</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset" title="(in PyTorch v2.5)"><em>Dataset</em></a>) – Validation dataset.</p></li>
<li><p><strong>callbacks</strong> (<em>List</em><em>[</em><a class="reference internal" href="callbacks.html#poutyne.Callback" title="poutyne.Callback"><em>Callback</em></a><em>]</em>) – List of callbacks that will be called during
training. These callbacks are added after those used in this method (see above). This allows to assume
that they are called after those.
(Default value = None)</p></li>
<li><p><strong>lr_schedulers</strong> – List of learning rate schedulers. (Default value = None)</p></li>
<li><p><strong>keep_only_last_best</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether only the last saved best checkpoint is kept. Applies only when
<cite>save_every_epoch</cite> is false.
(Default value = False)</p></li>
<li><p><strong>save_every_epoch</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether or not to save the model bundle’s model’s weights after
every epoch.
(Default value = False)</p></li>
<li><p><strong>disable_tensorboard</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether or not to disable the automatic tensorboard logging
callbacks.
(Default value = False)</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Seed used to make the sampling deterministic.
(Default value = 42)</p></li>
<li><p><strong>kwargs</strong> – Any keyword arguments to pass to <a class="reference internal" href="model.html#poutyne.Model.fit_dataset" title="poutyne.Model.fit_dataset"><code class="xref py py-func docutils literal notranslate"><span class="pre">fit_dataset()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of dict containing the history of each epoch.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="poutyne.ModelBundle.train_data">
<span class="sig-name descname"><span class="pre">train_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation_data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/poutyne/framework/model_bundle.html#ModelBundle.train_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#poutyne.ModelBundle.train_data" title="Link to this definition"></a></dt>
<dd><p>Trains or finetunes the model on data under the form of NumPy arrays or torch tensors. If a previous
training already occurred and lasted a total of <cite>n_previous</cite> epochs, then the model’s weights will be set to the
last checkpoint and the training will be resumed for epochs range (<cite>n_previous</cite>, <cite>epochs</cite>].</p>
<p>If the ModelBundle has logging enabled (i.e. self.logging is True), numerous callbacks will be automatically
included. Notably, two <a class="reference internal" href="callbacks.html#poutyne.ModelCheckpoint" title="poutyne.ModelCheckpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code></a> objects will take care of saving the last and every
new best (according to monitor mode) model weights in appropriate checkpoint files.
<a class="reference internal" href="callbacks.html#poutyne.OptimizerCheckpoint" title="poutyne.OptimizerCheckpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">OptimizerCheckpoint</span></code></a> and <a class="reference internal" href="callbacks.html#poutyne.LRSchedulerCheckpoint" title="poutyne.LRSchedulerCheckpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">LRSchedulerCheckpoint</span></code></a> will also respectively
handle the saving of the optimizer and LR scheduler’s respective states for future retrieval. Moreover, a
<a class="reference internal" href="callbacks.html#poutyne.AtomicCSVLogger" title="poutyne.AtomicCSVLogger"><code class="xref py py-class docutils literal notranslate"><span class="pre">AtomicCSVLogger</span></code></a> will save all available epoch statistics in an output .tsv file. Lastly, a
<a class="reference internal" href="callbacks.html#poutyne.TensorBoardLogger" title="poutyne.TensorBoardLogger"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorBoardLogger</span></code></a> handles automatic TensorBoard logging of various neural network
statistics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.5)"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.1)"><em>ndarray</em></a><em>] or </em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>] of </em><em>Union</em><em>[</em><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.5)"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.1)"><em>ndarray</em></a><em>]</em>) – Training dataset. Union[Tensor, ndarray] if the model has a single input.
Union[tuple, list] of Union[Tensor, ndarray] if the model has multiple inputs.</p></li>
<li><p><strong>y</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.5)"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.1)"><em>ndarray</em></a><em>] or </em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>] of </em><em>Union</em><em>[</em><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.5)"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.1)"><em>ndarray</em></a><em>]</em>) – Target. Union[Tensor, ndarray] if the model has a single output.
Union[tuple, list] of Union[Tensor, ndarray] if the model has multiple outputs.</p></li>
<li><p><strong>validation_data</strong> (Tuple[<code class="docutils literal notranslate"><span class="pre">x_val</span></code>, <code class="docutils literal notranslate"><span class="pre">y_val</span></code>]) – Same format as <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> previously described. Validation dataset on which to
evaluate the loss and any model metrics at the end of each epoch. The model will not be
trained on this data.
(Default value = None)</p></li>
<li><p><strong>callbacks</strong> (<em>List</em><em>[</em><a class="reference internal" href="callbacks.html#poutyne.Callback" title="poutyne.Callback"><em>Callback</em></a><em>]</em>) – List of callbacks that will be called during
training. These callbacks are added after those used in this method (see above). This allows to assume
that they are called after those.
(Default value = None)</p></li>
<li><p><strong>lr_schedulers</strong> – List of learning rate schedulers. (Default value = None)</p></li>
<li><p><strong>keep_only_last_best</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether only the last saved best checkpoint is kept. Applies only when
<cite>save_every_epoch</cite> is false.
(Default value = False)</p></li>
<li><p><strong>save_every_epoch</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether or not to save the model bundle’s model’s weights after
every epoch.
(Default value = False)</p></li>
<li><p><strong>disable_tensorboard</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether or not to disable the automatic tensorboard logging
callbacks.
(Default value = False)</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Seed used to make the sampling deterministic.
(Default value = 42)</p></li>
<li><p><strong>kwargs</strong> – Any keyword arguments to pass to <a class="reference internal" href="model.html#poutyne.Model.fit" title="poutyne.Model.fit"><code class="xref py py-func docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of dict containing the history of each epoch.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="poutyne.ModelBundle.load_checkpoint">
<span class="sig-name descname"><span class="pre">load_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span></span><a class="reference internal" href="_modules/poutyne/framework/model_bundle.html#ModelBundle.load_checkpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#poutyne.ModelBundle.load_checkpoint" title="Link to this definition"></a></dt>
<dd><p>Loads the model’s weights with the weights at a given checkpoint epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>checkpoint</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – <p>Which checkpoint to load the model’s weights form.</p>
<ul>
<li><p>If ‘best’, will load the best weights according to <code class="docutils literal notranslate"><span class="pre">monitor_metric</span></code> and <code class="docutils literal notranslate"><span class="pre">monitor_mode</span></code>.</p></li>
<li><p>If ‘last’, will load the last model checkpoint.</p></li>
<li><p>If int, will load the checkpoint of the specified epoch.</p></li>
<li><p>If a path (str), will load the model pickled state_dict weights (for instance, saved as
<code class="docutils literal notranslate"><span class="pre">torch.save(a_pytorch_network.state_dict(),</span> <span class="pre">&quot;./a_path.p&quot;)</span></code>).</p></li>
</ul>
</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether or not to print the checkpoint filename, and the best epoch
number and stats when checkpoint is ‘best’.
(Default value = False)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>If checkpoint is ‘best’, will return the best epoch stats, as per <a class="reference internal" href="#poutyne.ModelBundle.get_best_epoch_stats" title="poutyne.ModelBundle.get_best_epoch_stats"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_best_epoch_stats()</span></code></a>,
if checkpoint is ‘last’, will return the last epoch stats, if checkpoint is a int, will return the
epoch number stats, if a path, will return the stats of that specific checkpoint.
else None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="poutyne.ModelBundle.test">
<span class="sig-name descname"><span class="pre">test</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">test_generator</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/poutyne/framework/model_bundle.html#ModelBundle.test"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#poutyne.ModelBundle.test" title="Link to this definition"></a></dt>
<dd><p>Computes and returns the loss and the metrics of the model on a given test examples
generator.</p>
<p>If the ModelBundle has logging enabled (i.e. self.logging is True), a checkpoint (the best one by default)
is loaded and test and validation statistics are saved in a specific test output .tsv file. Otherwise, the
current weights of the network is used for testing and statistics are only shown in the standard output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>test_generator</strong> – Generator-like object for the test set. See <a class="reference internal" href="model.html#poutyne.Model.fit_generator" title="poutyne.Model.fit_generator"><code class="xref py py-func docutils literal notranslate"><span class="pre">fit_generator()</span></code></a> for
details on the types of generators supported.</p></li>
<li><p><strong>checkpoint</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>]</em>) – <p>Which model checkpoint weights to load for the test evaluation.</p>
<ul>
<li><p>If ‘best’, will load the best weights according to <code class="docutils literal notranslate"><span class="pre">monitor_metric</span></code> and <code class="docutils literal notranslate"><span class="pre">monitor_mode</span></code>.</p></li>
<li><p>If ‘last’, will load the last model checkpoint.</p></li>
<li><p>If int, will load the checkpoint of the specified epoch.</p></li>
<li><p>If a path (str), will load the model pickled state_dict weights (for instance, saved as
<code class="docutils literal notranslate"><span class="pre">torch.save(a_pytorch_network.state_dict(),</span> <span class="pre">&quot;./a_path.p&quot;)</span></code>).</p></li>
</ul>
<p>This argument has no effect when logging is disabled. (Default value = ‘best’)</p>
</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Seed used to make the sampling deterministic.
(Default value = 42)</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Prefix of the test log file. (Default value = ‘test’)</p></li>
<li><p><strong>kwargs</strong> – Any keyword arguments to pass to <a class="reference internal" href="model.html#poutyne.Model.evaluate_generator" title="poutyne.Model.evaluate_generator"><code class="xref py py-func docutils literal notranslate"><span class="pre">evaluate_generator()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<p>If the ModelBundle has logging enabled (i.e. self.logging is True), one callback will be automatically
included to save the test metrics. Moreover, a <a class="reference internal" href="callbacks.html#poutyne.AtomicCSVLogger" title="poutyne.AtomicCSVLogger"><code class="xref py py-class docutils literal notranslate"><span class="pre">AtomicCSVLogger</span></code></a> will save the test
metrics in an output .tsv file.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict sorting of all the test metrics values by their names.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="poutyne.ModelBundle.test_dataset">
<span class="sig-name descname"><span class="pre">test_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">test_dataset</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a></span></span><a class="reference internal" href="_modules/poutyne/framework/model_bundle.html#ModelBundle.test_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#poutyne.ModelBundle.test_dataset" title="Link to this definition"></a></dt>
<dd><p>Computes and returns the loss and the metrics of the model on a given test dataset.</p>
<p>If the ModelBundle has logging enabled (i.e. self.logging is True), a checkpoint (the best one by default)
is loaded and test and validation statistics are saved in a specific test output .tsv file. Otherwise, the
current weights of the network is used for testing and statistics are only shown in the standard output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>test_dataset</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset" title="(in PyTorch v2.5)"><em>Dataset</em></a>) – Test dataset.</p></li>
<li><p><strong>checkpoint</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>]</em>) – <p>Which model checkpoint weights to load for the test evaluation.</p>
<ul>
<li><p>If ‘best’, will load the best weights according to <code class="docutils literal notranslate"><span class="pre">monitor_metric</span></code> and <code class="docutils literal notranslate"><span class="pre">monitor_mode</span></code>.</p></li>
<li><p>If ‘last’, will load the last model checkpoint.</p></li>
<li><p>If int, will load the checkpoint of the specified epoch.</p></li>
<li><p>If a path (str), will load the model pickled state_dict weights (for instance, saved as
<code class="docutils literal notranslate"><span class="pre">torch.save(a_pytorch_network.state_dict(),</span> <span class="pre">&quot;./a_path.p&quot;)</span></code>).</p></li>
</ul>
<p>This argument has no effect when logging is disabled. (Default value = ‘best’)</p>
</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Seed used to make the sampling deterministic.
(Default value = 42)</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Prefix of the test log file. (Default value = ‘test’)</p></li>
<li><p><strong>kwargs</strong> – Any keyword arguments to pass to <a class="reference internal" href="model.html#poutyne.Model.evaluate_dataset" title="poutyne.Model.evaluate_dataset"><code class="xref py py-func docutils literal notranslate"><span class="pre">evaluate_dataset()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<p>If the ModelBundle has logging enabled (i.e. self.logging is True), one callback will be automatically
included to save the test metrics. Moreover, a <a class="reference internal" href="callbacks.html#poutyne.AtomicCSVLogger" title="poutyne.AtomicCSVLogger"><code class="xref py py-class docutils literal notranslate"><span class="pre">AtomicCSVLogger</span></code></a> will save the test
metrics in an output .tsv file.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict sorting of all the test metrics values by their names.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="poutyne.ModelBundle.test_data">
<span class="sig-name descname"><span class="pre">test_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a></span></span><a class="reference internal" href="_modules/poutyne/framework/model_bundle.html#ModelBundle.test_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#poutyne.ModelBundle.test_data" title="Link to this definition"></a></dt>
<dd><p>Computes and returns the loss and the metrics of the model on a given test dataset.</p>
<p>If the ModelBundle has logging enabled (i.e. self.logging is True), a checkpoint (the best one by default)
is loaded and test and validation statistics are saved in a specific test output .tsv file. Otherwise, the
current weights of the network is used for testing and statistics are only shown in the standard output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.5)"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.1)"><em>ndarray</em></a><em>] or </em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>] of </em><em>Union</em><em>[</em><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.5)"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.1)"><em>ndarray</em></a><em>]</em>) – Input to the model. Union[Tensor, ndarray] if the model has a single input.
Union[tuple, list] of Union[Tensor, ndarray] if the model has multiple inputs.</p></li>
<li><p><strong>y</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.5)"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.1)"><em>ndarray</em></a><em>] or </em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>] of </em><em>Union</em><em>[</em><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.5)"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.1)"><em>ndarray</em></a><em>]</em>) – Target, corresponding ground truth.
Union[Tensor, ndarray] if the model has a single output.
Union[tuple, list] of Union[Tensor, ndarray] if the model has multiple outputs.</p></li>
<li><p><strong>checkpoint</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>]</em>) – <p>Which model checkpoint weights to load for the test evaluation.</p>
<ul>
<li><p>If ‘best’, will load the best weights according to <code class="docutils literal notranslate"><span class="pre">monitor_metric</span></code> and <code class="docutils literal notranslate"><span class="pre">monitor_mode</span></code>.</p></li>
<li><p>If ‘last’, will load the last model checkpoint.</p></li>
<li><p>If int, will load the checkpoint of the specified epoch.</p></li>
<li><p>If a path (str), will load the model pickled state_dict weights (for instance, saved as
<code class="docutils literal notranslate"><span class="pre">torch.save(a_pytorch_network.state_dict(),</span> <span class="pre">&quot;./a_path.p&quot;)</span></code>).</p></li>
</ul>
<p>This argument has no effect when logging is disabled. (Default value = ‘best’)</p>
</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Seed used to make the sampling deterministic.
(Default value = 42)</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Prefix of the test log file. (Default value = ‘test’)</p></li>
<li><p><strong>kwargs</strong> – Any keyword arguments to pass to <a class="reference internal" href="model.html#poutyne.Model.evaluate" title="poutyne.Model.evaluate"><code class="xref py py-func docutils literal notranslate"><span class="pre">evaluate()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<p>If the ModelBundle has logging enabled (i.e. self.logging is True), one callback will be automatically
included to save the test metrics. Moreover, a <a class="reference internal" href="callbacks.html#poutyne.AtomicCSVLogger" title="poutyne.AtomicCSVLogger"><code class="xref py py-class docutils literal notranslate"><span class="pre">AtomicCSVLogger</span></code></a> will save the test
metrics in an output .tsv file.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict sorting of all the test metrics values by their names.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="poutyne.ModelBundle.infer">
<span class="sig-name descname"><span class="pre">infer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">generator</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></span><a class="reference internal" href="_modules/poutyne/framework/model_bundle.html#ModelBundle.infer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#poutyne.ModelBundle.infer" title="Link to this definition"></a></dt>
<dd><p>Returns the predictions of the network given batches of samples <code class="docutils literal notranslate"><span class="pre">x</span></code>, where the tensors are
converted into Numpy arrays.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>generator</strong> – Generator-like object for the dataset. The generator must yield a batch of
samples. See the <code class="xref py py-func docutils literal notranslate"><span class="pre">fit_generator()</span></code> method for details on the types of generators
supported. This should only yield input data <code class="docutils literal notranslate"><span class="pre">x</span></code> and NOT the target <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p></li>
<li><p><strong>checkpoint</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>]</em>) – <p>Which model checkpoint weights to load for the prediction.</p>
<ul>
<li><p>If ‘best’, will load the best weights according to <code class="docutils literal notranslate"><span class="pre">monitor_metric</span></code> and <code class="docutils literal notranslate"><span class="pre">monitor_mode</span></code>.</p></li>
<li><p>If ‘last’, will load the last model checkpoint.</p></li>
<li><p>If int, will load the checkpoint of the specified epoch.</p></li>
<li><p>If a path (str), will load the model pickled state_dict weights (for instance, saved as
<code class="docutils literal notranslate"><span class="pre">torch.save(a_pytorch_network.state_dict(),</span> <span class="pre">&quot;./a_path.p&quot;)</span></code>).</p></li>
</ul>
<p>This argument has no effect when logging is disabled. (Default value = ‘best’)</p>
</p></li>
<li><p><strong>kwargs</strong> – Any keyword arguments to pass to <a class="reference internal" href="model.html#poutyne.Model.predict_generator" title="poutyne.Model.predict_generator"><code class="xref py py-func docutils literal notranslate"><span class="pre">predict_generator()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Depends on the value of <code class="docutils literal notranslate"><span class="pre">concatenate_returns</span></code>. By default, (<code class="docutils literal notranslate"><span class="pre">concatenate_returns</span></code> is true),
the data structures (tensor, tuple, list, dict) returned as predictions for the batches are
merged together. In the merge, the tensors are converted into Numpy arrays and are then
concatenated together. If <code class="docutils literal notranslate"><span class="pre">concatenate_returns</span></code> is false, then a list of the predictions
for the batches is returned with tensors converted into Numpy arrays.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="poutyne.ModelBundle.infer_dataset">
<span class="sig-name descname"><span class="pre">infer_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></span><a class="reference internal" href="_modules/poutyne/framework/model_bundle.html#ModelBundle.infer_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#poutyne.ModelBundle.infer_dataset" title="Link to this definition"></a></dt>
<dd><p>Returns the inferred predictions of the network given a dataset, where the tensors are
converted into Numpy arrays.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset" title="(in PyTorch v2.5)"><em>Dataset</em></a>) – Dataset. Must not return <code class="docutils literal notranslate"><span class="pre">y</span></code>, just <code class="docutils literal notranslate"><span class="pre">x</span></code>.</p></li>
<li><p><strong>checkpoint</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>]</em>) – <p>Which model checkpoint weights to load for the prediction.</p>
<ul>
<li><p>If ‘best’, will load the best weights according to <code class="docutils literal notranslate"><span class="pre">monitor_metric</span></code> and <code class="docutils literal notranslate"><span class="pre">monitor_mode</span></code>.</p></li>
<li><p>If ‘last’, will load the last model checkpoint.</p></li>
<li><p>If int, will load the checkpoint of the specified epoch.</p></li>
<li><p>If a path (str), will load the model pickled state_dict weights (for instance, saved as
<code class="docutils literal notranslate"><span class="pre">torch.save(a_pytorch_network.state_dict(),</span> <span class="pre">&quot;./a_path.p&quot;)</span></code>).</p></li>
</ul>
<p>This argument has no effect when logging is disabled. (Default value = ‘best’)</p>
</p></li>
<li><p><strong>kwargs</strong> – Any keyword arguments to pass to <a class="reference internal" href="model.html#poutyne.Model.predict_dataset" title="poutyne.Model.predict_dataset"><code class="xref py py-func docutils literal notranslate"><span class="pre">predict_dataset()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Return the predictions in the format outputted by the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="poutyne.ModelBundle.infer_data">
<span class="sig-name descname"><span class="pre">infer_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></span><a class="reference internal" href="_modules/poutyne/framework/model_bundle.html#ModelBundle.infer_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#poutyne.ModelBundle.infer_data" title="Link to this definition"></a></dt>
<dd><p>Returns the inferred predictions of the network given a dataset <code class="docutils literal notranslate"><span class="pre">x</span></code>, where the tensors are
converted into Numpy arrays.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.5)"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.1)"><em>ndarray</em></a><em>] or </em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>] of </em><em>Union</em><em>[</em><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.5)"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.1)"><em>ndarray</em></a><em>]</em>) – Input to the model. Union[Tensor, ndarray] if the model has a single input.
Union[tuple, list] of Union[Tensor, ndarray] if the model has multiple inputs.</p></li>
<li><p><strong>checkpoint</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>]</em>) – <p>Which model checkpoint weights to load for the prediction.</p>
<ul>
<li><p>If ‘best’, will load the best weights according to <code class="docutils literal notranslate"><span class="pre">monitor_metric</span></code> and <code class="docutils literal notranslate"><span class="pre">monitor_mode</span></code>.</p></li>
<li><p>If ‘last’, will load the last model checkpoint.</p></li>
<li><p>If int, will load the checkpoint of the specified epoch.</p></li>
<li><p>If a path (str), will load the model pickled state_dict weights (for instance, saved as
<code class="docutils literal notranslate"><span class="pre">torch.save(a_pytorch_network.state_dict(),</span> <span class="pre">&quot;./a_path.p&quot;)</span></code>).</p></li>
</ul>
<p>This argument has no effect when logging is disabled. (Default value = ‘best’)</p>
</p></li>
<li><p><strong>kwargs</strong> – Any keyword arguments to pass to <a class="reference internal" href="model.html#poutyne.Model.predict" title="poutyne.Model.predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Return the predictions in the format outputted by the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="poutyne.ModelBundle.is_better_than">
<span class="sig-name descname"><span class="pre">is_better_than</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">another_model_bundle</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span></span><a class="reference internal" href="_modules/poutyne/framework/model_bundle.html#ModelBundle.is_better_than"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#poutyne.ModelBundle.is_better_than" title="Link to this definition"></a></dt>
<dd><p>Compare the results of the ModelBundle with another model bundle. To compare, both ModelBundles need to be
logged, monitor the same metric and the same monitor mode (“min” or “max”).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>another_model_bundle</strong> (<a class="reference internal" href="#poutyne.ModelBundle" title="poutyne.ModelBundle"><em>ModelBundle</em></a>) – Another Poutyne model bundle to compare results with.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Whether the ModelBundle is better than the ModelBundle to compare with.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="model.html" class="btn btn-neutral float-left" title="Model" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="metrics.html" class="btn btn-neutral float-right" title="Metrics" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018-2024, Frédérik Paradis.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-177874682-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-177874682-1');
  gtag('config', 'G-VJM5JZMZ01');
</script>


</body>
</html>